{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI-TFM_03.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu37c15PbiPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0b27e3ec-b9c2-47b7-bb4e-e2632e9685fd"
      },
      "source": [
        "from sklearn import tree\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "import graphviz \n",
        "\n",
        "# Algoritmo Random Forest\n",
        "def randomForest():\n",
        "  print(\"inicia Random Forest\")\n",
        "  rfc_object = rfc(n_estimators=200, random_state=0)\n",
        "  rfc_object.fit(train_features, train_labels)\n",
        "  predicted_labels = rfc_object.predict(test_features)\n",
        "  # se verifican resultados\n",
        "  print(classification_report(test_labels, predicted_labels))\n",
        "  print(confusion_matrix(test_labels, predicted_labels))\n",
        "  print(accuracy_score(test_labels, predicted_labels))\n",
        "\n",
        "  # Regresión lineal\n",
        "def regresionLineal():\n",
        "  print(\"inicia Regresión lineal\")\n",
        "  # Algoritmo\n",
        "  lr_object = LogisticRegression()\n",
        "  lr_object.fit(train_features, train_labels)\n",
        "  predicted_labels = lr_object.predict(test_features)\n",
        "  # se verifican resultados\n",
        "  print(classification_report(test_labels, predicted_labels))\n",
        "  print(confusion_matrix(test_labels, predicted_labels))\n",
        "  print(accuracy_score(test_labels, predicted_labels))\n",
        "  \n",
        "  \n",
        "# arbol de decision\n",
        "def arbolDecision():\n",
        "  print(\"inicia Arboles de decisión\")\n",
        "  # Create each decision tree (pruned and unpruned)\n",
        "  decisionTree_unpruned = tree.DecisionTreeClassifier()\n",
        "  decisionTree = tree.DecisionTreeClassifier(max_depth = 4)\n",
        "  # Fit each tree to our training data\n",
        "  decisionTree_unpruned = decisionTree_unpruned.fit(X=train_features, y=train_labels)\n",
        "  decisionTree = decisionTree.fit(X=train_features, y=train_labels)\n",
        "  # Generate PDF visual of decision tree\n",
        "  churnTree = tree.export_graphviz(decisionTree, out_file=None, \n",
        "                           feature_names = list(train_features.columns.values),  \n",
        "                           class_names = ['No churn', 'Churn'],\n",
        "                           filled=True, rounded=True,  \n",
        "                           special_characters=True)  \n",
        "  graph = graphviz.Source(churnTree)\n",
        "  graph.render('decision_tree.gv', view=True)\n",
        "  predicted_labels = decisionTree.predict(test_features)\n",
        "  # se verifican resultados\n",
        "  print(classification_report(test_labels, predicted_labels))\n",
        "  print(confusion_matrix(test_labels, predicted_labels))\n",
        "  print(accuracy_score(test_labels, predicted_labels))\n",
        "  \n",
        "\n",
        "#GradientBoostingClassifier\n",
        "def gradientBoost():\n",
        "  print(\"inicia Gradient Boosting Classifier\")\n",
        "  #Create Gradient Boosting Classifier\n",
        "  gb = GradientBoostingClassifier()\n",
        "  #Train the model using the training sets\n",
        "  gb.fit(train_features, train_labels)\n",
        "  #Predict the response for test dataset\n",
        "  predicted_labels = gb.predict(test_features)\n",
        "  print(classification_report(test_labels, predicted_labels))\n",
        "  print(confusion_matrix(test_labels, predicted_labels))\n",
        "  print(accuracy_score(test_labels, predicted_labels))\n",
        "  \n",
        "    # SVM  \n",
        "def SVM():\n",
        "  # Algoritmo\n",
        "  print(\"inicia Support Vector Machine\")\n",
        "  svc_object = svc(kernel='rbf', degree=8)\n",
        "  svc_object.fit(train_features, train_labels)\n",
        "  predicted_labels = svc_object.predict(test_features) \n",
        "  # se verifican resultados\n",
        "  print(classification_report(test_labels, predicted_labels))\n",
        "  print(confusion_matrix(test_labels, predicted_labels))\n",
        "  print(accuracy_score(test_labels, predicted_labels))\n",
        "\n",
        "# Deep Learning\n",
        "def redesNeuronales():\n",
        "  print(\"Inicia Deep Learning\")\n",
        "  # Se genera el modelo \n",
        "  modelo = Sequential()\n",
        "  #Se define un monitor de parada temprana para que el modelo deje de entrenar cuando ya no mejore\n",
        "  early_stopping_monitor = EarlyStopping(patience=3)\n",
        "  #Se obtienen las columnas de entrenamiento\n",
        "  scale = StandardScaler()\n",
        "  X_dataset = scale.fit_transform(features)\n",
        "  Y_dataset =labels.values \n",
        "  n_cols = X_dataset.shape[1]\n",
        "  #Se agregan las capas, aumentar el número de nodos en cada capa aumenta la capacidad del modelo pero por Collab lo dejare en esa cantidad\n",
        "  # La función de activación que utilizaremos es ReLU o activación lineal rectificada. \n",
        "  # Aunque se trata de dos piezas lineales, se ha demostrado que funciona bien en redes neuronales.\n",
        "  modelo.add (Dense (128, activation = 'relu', input_shape = (n_cols,))) \n",
        "  modelo.add( Dropout(0.3))\n",
        "  modelo.add (Dense (64, activation = 'relu')) \n",
        "  modelo.add( Dropout(0.25))\n",
        "  modelo.add (Dense (64, activation = 'sigmoid')) \n",
        "  modelo.add( Dropout(0.4))\n",
        "  modelo.add (Dense (64, activation = 'sigmoid')) \n",
        "  modelo.add( Dropout(0.25))\n",
        "  modelo.add (Dense (1, activation = 'sigmoid')) \n",
        "  #Una función de activación permite a los modelos tener en cuenta las relaciones no lineales. \n",
        "  #Por ejemplo, si predice la diabetes en los pacientes, pasar de los 10 a los 11 años es diferente a los de los 60 a los 61 años.\n",
        "  #La activación es 'softmax'. Softmax hace que la sum\n",
        "    # compilar el modelo utilizando la precisión para medir el rendimiento del modelo \n",
        "  modelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  resultado=modelo.fit(X_dataset, Y_dataset, batch_size=30, epochs=30, validation_split=0.4, callbacks=[early_stopping_monitor])\n",
        "\n",
        "  predicted_labels = modelo.predict(test_features)\n",
        "  print(classification_report(test_labels, predicted_labels.round()))\n",
        "  print(confusion_matrix(test_labels, predicted_labels.round()))\n",
        "  print(accuracy_score(test_labels, predicted_labels.round()))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KefA9ZvZWdT",
        "colab_type": "code",
        "outputId": "ae2ae1f2-b1b6-4da0-a102-fa06cb9a10f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "source": [
        "!pip install turicreate\n",
        "!pip install lifetimes\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import time\n",
        "import turicreate as tc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lifetimes.utils import *\n",
        "from lifetimes import BetaGeoFitter,GammaGammaFitter\n",
        "from lifetimes.plotting import plot_probability_alive_matrix, plot_frequency_recency_matrix, plot_period_transactions, plot_cumulative_transactions,plot_incremental_transactions\n",
        "from lifetimes.generate_data import beta_geometric_nbd_model\n",
        "from lifetimes.plotting import plot_calibration_purchases_vs_holdout_purchases, plot_period_transactions,plot_history_alive\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "## Algoritmos de ML\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier as rfc\n",
        "from sklearn.svm import SVC as svc \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from sklearn import tree\n",
        "import graphviz \n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn import svm\n",
        "from sklearn import ensemble\n",
        "from sklearn import neighbors\n",
        "from sklearn import linear_model\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: turicreate in /usr/local/lib/python3.6/dist-packages (5.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from turicreate) (1.12.0)\n",
            "Requirement already satisfied: coremltools==3.0b3 in /usr/local/lib/python3.6/dist-packages (from turicreate) (3.0b3)\n",
            "Requirement already satisfied: prettytable==0.7.2 in /usr/local/lib/python3.6/dist-packages (from turicreate) (0.7.2)\n",
            "Requirement already satisfied: resampy==0.2.1 in /usr/local/lib/python3.6/dist-packages (from turicreate) (0.2.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from turicreate) (1.3.1)\n",
            "Requirement already satisfied: pandas>=0.23.2 in /usr/local/lib/python3.6/dist-packages (from turicreate) (0.24.2)\n",
            "Requirement already satisfied: numpy==1.16.4 in /usr/local/lib/python3.6/dist-packages (from turicreate) (1.16.4)\n",
            "Requirement already satisfied: decorator>=4.0.9 in /usr/local/lib/python3.6/dist-packages (from turicreate) (4.4.0)\n",
            "Requirement already satisfied: pillow>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from turicreate) (6.1.0)\n",
            "Requirement already satisfied: requests>=2.9.1 in /usr/local/lib/python3.6/dist-packages (from turicreate) (2.21.0)\n",
            "Requirement already satisfied: mxnet<1.2.0,>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from turicreate) (1.1.0.post0)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from coremltools==3.0b3->turicreate) (3.7.1)\n",
            "Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.6/dist-packages (from resampy==0.2.1->turicreate) (0.40.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.2->turicreate) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.2->turicreate) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.9.1->turicreate) (2019.6.16)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.9.1->turicreate) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.9.1->turicreate) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.9.1->turicreate) (3.0.4)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet<1.2.0,>=1.1.0->turicreate) (0.8.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.1.0->coremltools==3.0b3->turicreate) (41.2.0)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.32->resampy==0.2.1->turicreate) (0.29.0)\n",
            "Requirement already satisfied: lifetimes in /usr/local/lib/python3.6/dist-packages (0.11.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from lifetimes) (0.24.2)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from lifetimes) (1.16.4)\n",
            "Requirement already satisfied: autograd>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from lifetimes) (1.3)\n",
            "Requirement already satisfied: dill>=0.2.6 in /usr/local/lib/python3.6/dist-packages (from lifetimes) (0.3.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from lifetimes) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->lifetimes) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->lifetimes) (2.5.3)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from autograd>=1.2.0->lifetimes) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.24.0->lifetimes) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y7BCrBCZl-o",
        "colab_type": "code",
        "outputId": "5b782ccf-120f-42d7-9ff3-409d0670414f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "url = 'https://github.com/masdatascience/TFM-AI/blob/master/transacciones.xlsx?raw=true'\n",
        "datos_modelo_completo = pd.ExcelFile(url)\n",
        "datos_facturacion = pd.read_excel(datos_modelo_completo, sheet_name='transacciones')\n",
        "# Se elimian los datos nulos de las dimensiones importantes del analisis que son productos y clientes\n",
        "#datos_facturacion = datos_facturacion.dropna(subset=['customer_id'])\n",
        "#datos_facturacion = datos_facturacion.dropna(subset=['product_id'])\n",
        "# Se elimina posibles chargeback que se presenten\n",
        "url1 = 'https://github.com/masdatascience/TFM-AI/blob/master/data_model_completo.xlsx?raw=true'\n",
        "datos_modelo_completo = pd.ExcelFile(url1)\n",
        "#datos_facturacion = datos_facturacion.loc[datos_facturacion['total_value'] > 0]\n",
        "datos_producto = pd.read_excel(datos_modelo_completo, sheet_name='product')\n",
        "datos_clientes = pd.read_excel(datos_modelo_completo, sheet_name='customer')\n",
        "print(\"datos productos: \"+str(datos_producto.shape))\n",
        "print(\"datos clientes: \"+str(datos_clientes.shape))\n",
        "print(\"datos facturación: \"+str(datos_facturacion.shape))\n",
        "# se visualiza el número de comrpas que tiene un cliente\n",
        "datos_clientes.groupby('customer_id').size().value_counts()\n",
        "datos_facturacion.groupby('customer_id').size().value_counts()\n",
        "  "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datos productos: (32951, 10)\n",
            "datos clientes: (96352, 4)\n",
            "datos facturación: (100010, 11)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     91370\n",
              "2      3643\n",
              "3       327\n",
              "4        55\n",
              "5        14\n",
              "6         6\n",
              "7         3\n",
              "16        1\n",
              "10        1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqqF7UkPZqzp",
        "colab_type": "text"
      },
      "source": [
        "3.1 MARCAJE CHURN \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMdhAqQzZsI5",
        "colab_type": "code",
        "outputId": "f9d58409-d5d1-4d03-fdd3-c84b7ed10098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        }
      },
      "source": [
        "datos_facturacion['date'] = pd.to_datetime(datos_facturacion['order_purchase_timestamp']).dt.date\n",
        "datos_facturacion = datos_facturacion.drop('order_purchase_timestamp',axis=1)\n",
        "# se realiza un subconjunto de columnas con los cuales se analizará el comportamiento de compra\n",
        "transaction_data = datos_facturacion[['customer_id','date','price']]\n",
        "# se crea el modelo RFM\n",
        "summary = summary_data_from_transaction_data(transaction_data,'customer_id','date',monetary_value_col='price',)\n",
        "t=1\n",
        "bgf = BetaGeoFitter(penalizer_coef=0.0)\n",
        "bgf.fit(summary['frequency'], summary['recency'], summary['T'])\n",
        "plot_frequency_recency_matrix(bgf);\n",
        "plot_probability_alive_matrix(bgf)\n",
        "plot_period_transactions(bgf).set_yscale('log');\n",
        "summary['predicted_purchases'] = bgf.conditional_expected_number_of_purchases_up_to_time(t, summary['frequency'], summary['recency'], summary['T'])\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
            "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  \"Adding an axes using the same arguments as a previous axes \"\n",
            "/usr/local/lib/python3.6/dist-packages/lifetimes/generate_data.py:54: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  next_purchase_in = random.exponential(scale=1.0 / l)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEiCAYAAAAf0W5kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHNMgICKSYxoERERy7AWvruXfBvqb4wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAETCAYAAAAs4pGmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWUcI+UwUP8UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7cIcUTRaDjI",
        "colab_type": "code",
        "outputId": "58bc772c-f40a-44c1-a98a-8bcb4284ba71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        }
      },
      "source": [
        "summary_cal_holdout = calibration_and_holdout_data(datos_facturacion, 'customer_id', 'date',calibration_period_end='2017-09-03', observation_period_end='2018-09-03' )\n",
        "bgf.fit(summary_cal_holdout['frequency_cal'], summary_cal_holdout['recency_cal'], summary_cal_holdout['T_cal'])\n",
        "plot_cumulative_transactions(bgf, datos_facturacion, 'date', 'customer_id', 730, 365);\n",
        "plot_incremental_transactions(bgf, datos_facturacion, 'date', 'customer_id', 730, 365);\n",
        "plot_calibration_purchases_vs_holdout_purchases(bgf, summary_cal_holdout);\n",
        "datos_clientes.groupby('customer_id').size().value_counts()\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
            "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  \"Adding an axes using the same arguments as a previous axes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    95844\n",
              "2      248\n",
              "3        4\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkZwgkiRJkkb+AQ4Y1ykzOjjxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aDI_Qqvaltz",
        "colab_type": "code",
        "outputId": "58a2f704-1a7b-4b1a-93d6-133f12a90981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "df = summary[summary['frequency']>0]\n",
        "df['prob_alive'] = bgf.conditional_probability_alive(df['frequency'],df['recency'],df['T'])\n",
        "sns.distplot(df['prob_alive']);\n",
        "df['churn'] = ['churned' if p < .1 else 'not churned' for p in df['prob_alive']]\n",
        "sns.countplot(df['churn']);\n",
        "sns.distplot(df[df['churn']=='not churned']['prob_alive']).set_title('Probability alive, not churned');\n",
        "df['churn'][(df['prob_alive']>=.1) & (df['prob_alive']<.2)] = \"high risk\"\n",
        "df['churn'].value_counts()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "churned        1928\n",
              "high risk        84\n",
              "not churned      73\n",
              "Name: churn, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEXCAYAAABVr8jJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpRcioZFao-m",
        "colab_type": "text"
      },
      "source": [
        "3.2 Churn prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn6xeN5AapnG",
        "colab_type": "code",
        "outputId": "d0f43fff-0d8f-4dc3-cf10-4d6a8ccc7ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "print(summary.median())\n",
        "df['is_churn'] = np.where( (df['frequency']<1) & (df['T']>400) & (df['recency']<1) & (df['recency']<0.000044), 1, 0) \n",
        "summary['is_churn'] = np.where( (summary['frequency']<1) & (summary['T']>400) & (summary['recency']<1) & (summary['recency']<0.000044), 1, 0) \n",
        "prueba_clientes = pd.merge(datos_clientes,summary[['is_churn']],on='customer_id', how='left')\n",
        "prueba_clientes = pd.merge(prueba_clientes,datos_facturacion[['customer_id','seller_id']].drop_duplicates(),on='customer_id', how='left')\n",
        "prueba_clientes['is_churn'].fillna(0, inplace=True)\n",
        "prueba_clientes['seller_id'].fillna(0, inplace=True)\n",
        "print(prueba_clientes.count())\n",
        "prueba_clientes.groupby('is_churn').count()\n",
        "prueba_clientes['is_churn'].mean()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frequency                0.000000\n",
            "recency                  0.000000\n",
            "T                      227.000000\n",
            "monetary_value           0.000000\n",
            "predicted_purchases      0.000054\n",
            "dtype: float64\n",
            "customer_id                 100232\n",
            "customer_state              100232\n",
            "customer_city               100232\n",
            "customer_zip_code_prefix    100232\n",
            "is_churn                    100232\n",
            "seller_id                   100232\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17545294915795354"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEQooHWzat7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def labelDatase(dataset):\n",
        "\n",
        "  le = preprocessing.LabelEncoder()\n",
        "\n",
        "  for column_name in dataset.columns:\n",
        "        if dataset[column_name].dtype == object:\n",
        "            dataset[column_name] = le.fit_transform(dataset[column_name])\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "  return dataset\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTgiNJ04dUyU",
        "colab_type": "code",
        "outputId": "9721fdf3-b048-43b7-859a-6f2177d82ba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "print(summary.median())\n",
        "df['is_churn'] = np.where( (df['frequency']<1) & (df['T']>400) & (df['recency']<1) & (df['recency']<0.000044), 1, 0) \n",
        "summary['is_churn'] = np.where( (summary['frequency']<1) & (summary['T']>400) & (summary['recency']<1) & (summary['recency']<0.000044), 1, 0) \n",
        "\n",
        "prueba_clientes = pd.merge(datos_clientes,summary[['is_churn']],on='customer_id', how='left')\n",
        "prueba_clientes = pd.merge(prueba_clientes,datos_facturacion[['customer_id','seller_id']].drop_duplicates(),on='customer_id', how='left')\n",
        "prueba_clientes['is_churn'].fillna(0, inplace=True)\n",
        "prueba_clientes['seller_id'].fillna(0, inplace=True)\n",
        "print(prueba_clientes.count())\n",
        "prueba_clientes.groupby('is_churn').count()\n",
        "prueba_clientes['is_churn'].mean()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frequency                0.000000\n",
            "recency                  0.000000\n",
            "T                      227.000000\n",
            "monetary_value           0.000000\n",
            "predicted_purchases      0.000054\n",
            "is_churn                 0.000000\n",
            "dtype: float64\n",
            "customer_id                 100232\n",
            "customer_state              100232\n",
            "customer_city               100232\n",
            "customer_zip_code_prefix    100232\n",
            "is_churn                    100232\n",
            "seller_id                   100232\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17545294915795354"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-XJy-aObg-D",
        "colab_type": "code",
        "outputId": "9b818213-1f8a-4af1-a436-e0ce27a553d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "enconder = LabelEncoder()\n",
        "\n",
        "\n",
        "dataset =  prueba_clientes.drop(['customer_id','customer_city','seller_id'], axis=1)\n",
        "ds_customer_city = pd.get_dummies(prueba_clientes.customer_city).iloc[:,1:]\n",
        "#ds_seller_id = pd.get_dummies(prueba_clientes.seller_id.astype('category').cat.codes).iloc[:,1:]\n",
        "ds_seller_id = pd.get_dummies(prueba_clientes.seller_id).iloc[:,1:]\n",
        "customer = pd.concat([dataset,ds_customer_city,ds_seller_id], axis=1)\n",
        "#customer['customer_id']= enconder.fit_transform(customer[\"customer_id\"])\n",
        "customer['customer_state']= enconder.fit_transform(customer[\"customer_state\"])\n",
        "print(customer.shape)\n",
        "customer.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100232, 7216)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_state</th>\n",
              "      <th>customer_zip_code_prefix</th>\n",
              "      <th>is_churn</th>\n",
              "      <th>abadiania</th>\n",
              "      <th>abaete</th>\n",
              "      <th>abaetetuba</th>\n",
              "      <th>abaiara</th>\n",
              "      <th>abaira</th>\n",
              "      <th>abare</th>\n",
              "      <th>abatia</th>\n",
              "      <th>abdon batista</th>\n",
              "      <th>abelardo luz</th>\n",
              "      <th>abrantes</th>\n",
              "      <th>abre campo</th>\n",
              "      <th>abreu e lima</th>\n",
              "      <th>acaiaca</th>\n",
              "      <th>acailandia</th>\n",
              "      <th>acajutiba</th>\n",
              "      <th>acarau</th>\n",
              "      <th>acari</th>\n",
              "      <th>acegua</th>\n",
              "      <th>acopiara</th>\n",
              "      <th>acreuna</th>\n",
              "      <th>acu</th>\n",
              "      <th>acucena</th>\n",
              "      <th>adamantina</th>\n",
              "      <th>adhemar de barros</th>\n",
              "      <th>adolfo</th>\n",
              "      <th>adrianopolis</th>\n",
              "      <th>adustina</th>\n",
              "      <th>afogados da ingazeira</th>\n",
              "      <th>afonso claudio</th>\n",
              "      <th>afranio</th>\n",
              "      <th>agisse</th>\n",
              "      <th>agrestina</th>\n",
              "      <th>agrolandia</th>\n",
              "      <th>agronomica</th>\n",
              "      <th>agua boa</th>\n",
              "      <th>agua branca</th>\n",
              "      <th>agua clara</th>\n",
              "      <th>...</th>\n",
              "      <th>fd386aa7bed2af3c7035c65506c9b4a3</th>\n",
              "      <th>fd435faa3c0422b60440ea3480d0e77c</th>\n",
              "      <th>fdaaf5bfda82b7b80535610c831b8d09</th>\n",
              "      <th>fdb9095204a334cd8872252ffec6f2db</th>\n",
              "      <th>fde0cc9ea29c8ccfc0a2c22256a58c71</th>\n",
              "      <th>fdf736c18c589ed030e058312203e1b2</th>\n",
              "      <th>fe19dce63ae80346207c6c55713d1023</th>\n",
              "      <th>fe1b067411b8c5066e962aa146ccee03</th>\n",
              "      <th>fe1bbc5feda5c8979a8a1b3b2512d5a6</th>\n",
              "      <th>fe2032dab1a61af8794248c8196565c9</th>\n",
              "      <th>fe26f3ecb51a15e6d8335cd92da42562</th>\n",
              "      <th>fe49ee029e61e789a1f3a5525f57ba8d</th>\n",
              "      <th>fe4cd9461203cee790d36792420b310f</th>\n",
              "      <th>fe701d88b67eaca109dffd464d1be9f9</th>\n",
              "      <th>fe8055980a4ff7f64ed889c2b5926929</th>\n",
              "      <th>fe87f472055fbcf1d7e691c00b1560dc</th>\n",
              "      <th>fe9d9cf8631285d5982c6e2cf27fb114</th>\n",
              "      <th>feb793c88d836c3a75efa4b5a3465d70</th>\n",
              "      <th>febab0275244b9a49a623f0bd613ca2f</th>\n",
              "      <th>fec6275253471ace26d209bbaa64cd0f</th>\n",
              "      <th>fec6912baad85d41729669edd6b4d3b8</th>\n",
              "      <th>fec8cd45395b3cb0c2b173d7739706a1</th>\n",
              "      <th>fedaedd3ca31d56ab33e92035e4b361c</th>\n",
              "      <th>fedf2c1386e137f296b3bbf3b635e69d</th>\n",
              "      <th>ff063b022a9a0aab91bad2c9088760b7</th>\n",
              "      <th>ff1e15b778c700abdd4d239b81ac466d</th>\n",
              "      <th>ff1fb4c404b2efe68b03350a8dc24122</th>\n",
              "      <th>ff314fa6033cc68ec451c47aee2d6ba4</th>\n",
              "      <th>ff4e2d38692ce827b1a4f4b8196e680d</th>\n",
              "      <th>ff4ea69c2a729e83e63c7579e4ef8170</th>\n",
              "      <th>ff69aa92bb6b1bf9b8b7a51c2ed9cf8b</th>\n",
              "      <th>ff82e8873fba613f2261a9acc896fd84</th>\n",
              "      <th>ffa6adafb71b807dc13159e26431354c</th>\n",
              "      <th>ffad1e7127fb622cb64a900751590acd</th>\n",
              "      <th>ffc470761de7d0232558ba5e786e57b7</th>\n",
              "      <th>ffcfefa19b08742c5d315f2791395ee5</th>\n",
              "      <th>ffdd9f82b9a447f6f8d4b91554cc7dd3</th>\n",
              "      <th>ffeee66ac5d5a62fe688b9d26f83f534</th>\n",
              "      <th>fffd5413c0700ac820c7069d66d98c89</th>\n",
              "      <th>ffff564a4f9085cd26170f4732393726</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>7787</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "      <td>6053</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23</td>\n",
              "      <td>88115</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>66812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25</td>\n",
              "      <td>18040</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 7216 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   customer_state  ...  ffff564a4f9085cd26170f4732393726\n",
              "0              25  ...                                 0\n",
              "1              25  ...                                 0\n",
              "2              23  ...                                 0\n",
              "3              13  ...                                 0\n",
              "4              25  ...                                 0\n",
              "\n",
              "[5 rows x 7216 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MsmJf9Uc4Vq",
        "colab_type": "code",
        "outputId": "c53c9320-2585-4c06-c801-dc382015d9bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "datos_facturacion.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_id</th>\n",
              "      <th>customer_order_id</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>seller_id</th>\n",
              "      <th>order_status</th>\n",
              "      <th>order_approved_at</th>\n",
              "      <th>order_delivered_carrier_date</th>\n",
              "      <th>order_delivered_customer_date</th>\n",
              "      <th>order_estimated_delivery_date</th>\n",
              "      <th>price</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7f39ba4c9052be115350065d07583cac</td>\n",
              "      <td>d7fc82cbeafea77bd0a8fbbf6296e387</td>\n",
              "      <td>9de5797cddb92598755a0f76383ddbbb</td>\n",
              "      <td>0015a82c2db000af6aaaf3ae2ecb0532</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2017-10-18 23:56:20</td>\n",
              "      <td>2017-10-20 14:29:01</td>\n",
              "      <td>2017-10-27 16:46:05</td>\n",
              "      <td>2017-11-09</td>\n",
              "      <td>89500</td>\n",
              "      <td>2017-10-18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9dc8d1a6f16f1b89874c29c9d8d30447</td>\n",
              "      <td>d9442164acf4b03109425633efaa0cfc</td>\n",
              "      <td>9915eb9f74b6c11aaf04833f65b00e93</td>\n",
              "      <td>0015a82c2db000af6aaaf3ae2ecb0532</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2017-10-12 13:49:22</td>\n",
              "      <td>2017-10-17 15:42:42</td>\n",
              "      <td>2017-10-24 20:17:44</td>\n",
              "      <td>2017-11-06</td>\n",
              "      <td>89500</td>\n",
              "      <td>2017-10-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d455a8cb295653b55abda06d434ab492</td>\n",
              "      <td>944b72539d7e1f7f7fc6e46639ef1fe3</td>\n",
              "      <td>3c7e305796add66698959fc7ad176f6b</td>\n",
              "      <td>0015a82c2db000af6aaaf3ae2ecb0532</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2017-09-27 22:24:16</td>\n",
              "      <td>2017-09-29 15:53:03</td>\n",
              "      <td>2017-10-07 16:12:47</td>\n",
              "      <td>2017-10-30</td>\n",
              "      <td>89500</td>\n",
              "      <td>2017-09-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>006e43460a55bc60c0a437521e426529</td>\n",
              "      <td>23bfd4316e261786deed5a08231c75bc</td>\n",
              "      <td>1df0a296f852bdf1a17b085730f4b894</td>\n",
              "      <td>001cca7ae9ae17fb1caed9dfb1094831</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2017-05-11 01:30:22</td>\n",
              "      <td>2017-05-12 12:26:32</td>\n",
              "      <td>2017-05-19 09:51:17</td>\n",
              "      <td>2017-06-02</td>\n",
              "      <td>9900</td>\n",
              "      <td>2017-05-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00dfb074b5c910fbd08e04691c4b712f</td>\n",
              "      <td>a5ced4926d7d8fa71e9be2b007720356</td>\n",
              "      <td>94ea9edee3656707894565f35cb8570d</td>\n",
              "      <td>001cca7ae9ae17fb1caed9dfb1094831</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2017-06-08 19:55:19</td>\n",
              "      <td>2017-06-09 15:12:41</td>\n",
              "      <td>2017-06-15 09:03:59</td>\n",
              "      <td>2017-07-10</td>\n",
              "      <td>9950</td>\n",
              "      <td>2017-06-08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           order_id  ...        date\n",
              "0  7f39ba4c9052be115350065d07583cac  ...  2017-10-18\n",
              "1  9dc8d1a6f16f1b89874c29c9d8d30447  ...  2017-10-12\n",
              "2  d455a8cb295653b55abda06d434ab492  ...  2017-09-26\n",
              "3  006e43460a55bc60c0a437521e426529  ...  2017-05-11\n",
              "4  00dfb074b5c910fbd08e04691c4b712f  ...  2017-06-08\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAnUJkr3bloz",
        "colab_type": "code",
        "outputId": "351a644a-7f52-4905-8395-95d96d9a652d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "## Prueba 1  (City - Seller)\n",
        "\n",
        " \n",
        "print(summary.median())\n",
        "\n",
        "## Marco los churn\n",
        "summary['is_churn'] = np.where( (summary['frequency']<1) & (summary['T']>400) & (summary['recency']<1) & (summary['recency']<0.000044), 1, 0) \n",
        "prueba_clientes = pd.merge(datos_clientes,summary[['is_churn']],on='customer_id', how='left')\n",
        "## traigo los vendedores\n",
        "prueba_clientes = pd.merge(prueba_clientes,datos_facturacion[['customer_id','seller_id']].drop_duplicates(),on='customer_id', how='left')\n",
        "## Traigo los productos\n",
        "\n",
        "# Completo la información de los churn con 0\n",
        "prueba_clientes['is_churn'].fillna(0, inplace=True)\n",
        "\n",
        "# Completo la información de los vendedores con un vendedor default\n",
        "prueba_clientes['seller_id'].fillna(0, inplace=True)\n",
        "#prueba_clientes['product_id'].fillna(0, inplace=True)\n",
        "\n",
        "# imprimio numero de clientes, cuantos son churn y que % es del total \n",
        "print(prueba_clientes.count())\n",
        "prueba_clientes.groupby('is_churn').count()\n",
        "prueba_clientes['is_churn'].mean()\n",
        "\n",
        "\n",
        "\n",
        "# codificacione de las variables\n",
        "enconder = LabelEncoder()\n",
        "# obtengo un dataset sin la información las columnas a transformar\n",
        "\n",
        "#Obtengo el dataset de trabajo \n",
        "customer = prueba_clientes.copy()\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frequency                0.000000\n",
            "recency                  0.000000\n",
            "T                      227.000000\n",
            "monetary_value           0.000000\n",
            "predicted_purchases      0.000054\n",
            "is_churn                 0.000000\n",
            "dtype: float64\n",
            "customer_id                 100232\n",
            "customer_state              100232\n",
            "customer_city               100232\n",
            "customer_zip_code_prefix    100232\n",
            "is_churn                    100232\n",
            "seller_id                   100232\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hQ225w5tYpn",
        "colab_type": "code",
        "outputId": "42a9b222-09e0-4087-c75b-97113d8fa7a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "\n",
        "# codifico verticalmente \n",
        "customer['customer_state']= enconder.fit_transform(customer[\"customer_state\"])\n",
        "customer['customer_city']= enconder.fit_transform(customer[\"customer_city\"])\n",
        "customer['seller_id']= enconder.fit_transform( customer['seller_id'].astype('|S'))\n",
        "# Genero las variables de codificacion \n",
        "# se obtiene X y Y , además los datasets de entrenamiento y pruebas\n",
        "features = customer.drop(['customer_id','is_churn'], axis=1)\n",
        "labels = customer['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "\n",
        "customer.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100232, 4)\n",
            "(100232,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>customer_state</th>\n",
              "      <th>customer_city</th>\n",
              "      <th>customer_zip_code_prefix</th>\n",
              "      <th>is_churn</th>\n",
              "      <th>seller_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>\n",
              "      <td>25</td>\n",
              "      <td>655</td>\n",
              "      <td>7787</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000b849f77a49e4a4ce2b2a4ca5be3f</td>\n",
              "      <td>25</td>\n",
              "      <td>2594</td>\n",
              "      <td>6053</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000f46a3911fa3c0805444483337064</td>\n",
              "      <td>23</td>\n",
              "      <td>3520</td>\n",
              "      <td>88115</td>\n",
              "      <td>1.0</td>\n",
              "      <td>732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000f6ccb0745a6a4b88665a16c9f078</td>\n",
              "      <td>13</td>\n",
              "      <td>448</td>\n",
              "      <td>66812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0004aac84e0df4da2b147fca70cf8255</td>\n",
              "      <td>25</td>\n",
              "      <td>3758</td>\n",
              "      <td>18040</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        customer_id  customer_state  ...  is_churn  seller_id\n",
              "0  0000366f3b9a7992bf8c76cfdf3221e2              25  ...       0.0       2644\n",
              "1  0000b849f77a49e4a4ce2b2a4ca5be3f              25  ...       0.0        228\n",
              "2  0000f46a3911fa3c0805444483337064              23  ...       1.0        732\n",
              "3  0000f6ccb0745a6a4b88665a16c9f078              13  ...       0.0       2891\n",
              "4  0004aac84e0df4da2b147fca70cf8255              25  ...       0.0       1375\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7o17FCOtk8j",
        "colab_type": "code",
        "outputId": "70567854-8035-4139-f5eb-804e1e5c10be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "''''''\n",
        "#randomForest()\n",
        "#regresionLineal()\n",
        "#arbolDecision()\n",
        "#gradientBoost()\n",
        "#redesNeuronales()\n",
        "#SVM()\n",
        " "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNpzdcdEwhqf",
        "colab_type": "code",
        "outputId": "08fc241e-aafc-43b7-d29e-63ea100a43fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Prueba 2 -  (City - Seller - Producto)\n",
        "\n",
        " \n",
        "print(summary.median())\n",
        "\n",
        "## Marco los churn\n",
        "summary['is_churn'] = np.where( (summary['frequency']<1) & (summary['T']>400) & (summary['recency']<1) & (summary['recency']<0.000044), 1, 0) \n",
        "prueba_clientes = pd.merge(datos_clientes,summary[['is_churn']],on='customer_id', how='left')\n",
        "## traigo los vendedores\n",
        "prueba_clientes = pd.merge(prueba_clientes,datos_facturacion[['customer_id','seller_id']].drop_duplicates(),on='customer_id', how='left')\n",
        "## Traigo los productos\n",
        "\n",
        "# Completo la información de los churn con 0\n",
        "prueba_clientes['is_churn'].fillna(0, inplace=True)\n",
        "\n",
        "# Completo la información de los vendedores con un vendedor default\n",
        "prueba_clientes['seller_id'].fillna(0, inplace=True)\n",
        "#prueba_clientes['product_id'].fillna(0, inplace=True)\n",
        "\n",
        "# imprimio numero de clientes, cuantos son churn y que % es del total \n",
        "print(prueba_clientes.count())\n",
        "prueba_clientes.groupby('is_churn').count()\n",
        "prueba_clientes['is_churn'].mean()\n",
        "\n",
        "\n",
        "\n",
        "# codificacione de las variables\n",
        "enconder = LabelEncoder()\n",
        "# obtengo un dataset sin la información las columnas a transformar\n",
        "\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frequency                0.000000\n",
            "recency                  0.000000\n",
            "T                      227.000000\n",
            "monetary_value           0.000000\n",
            "predicted_purchases      0.000054\n",
            "is_churn                 0.000000\n",
            "dtype: float64\n",
            "customer_id                 100232\n",
            "customer_state              100232\n",
            "customer_city               100232\n",
            "customer_zip_code_prefix    100232\n",
            "is_churn                    100232\n",
            "seller_id                   100232\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9ETG39Xwsti",
        "colab_type": "code",
        "outputId": "f186de18-38b2-4abb-9d0f-ced31408cf0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "url2 = 'https://github.com/masdatascience/TFM-AI/blob/master/data_model_completo.xlsx?raw=true'\n",
        "datos_fac = pd.ExcelFile(url2)\n",
        "datos_fac_prod = pd.read_excel(datos_fac, sheet_name='fac_txn')\n",
        "datos_fac_prod= datos_fac_prod[['customer_id','product_id']]\n",
        "datos_fac_prod['product_id']= enconder.fit_transform( datos_fac_prod['product_id'])\n",
        "prueba_clientes = pd.merge(prueba_clientes,datos_fac_prod.drop_duplicates(),on='customer_id', how='left')\n",
        "#Obtengo el dataset de trabajo     \n",
        "customer = prueba_clientes.copy()\n",
        "customer.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>customer_state</th>\n",
              "      <th>customer_city</th>\n",
              "      <th>customer_zip_code_prefix</th>\n",
              "      <th>is_churn</th>\n",
              "      <th>seller_id</th>\n",
              "      <th>product_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>\n",
              "      <td>SP</td>\n",
              "      <td>cajamar</td>\n",
              "      <td>7787</td>\n",
              "      <td>0.0</td>\n",
              "      <td>da8622b14eb17ae2831f4ac5b9dab84a</td>\n",
              "      <td>7158.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000b849f77a49e4a4ce2b2a4ca5be3f</td>\n",
              "      <td>SP</td>\n",
              "      <td>osasco</td>\n",
              "      <td>6053</td>\n",
              "      <td>0.0</td>\n",
              "      <td>138dbe45fc62f1e244378131a6801526</td>\n",
              "      <td>10466.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000f46a3911fa3c0805444483337064</td>\n",
              "      <td>SC</td>\n",
              "      <td>sao jose</td>\n",
              "      <td>88115</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3d871de0142ce09b7081e2b9d1733cb1</td>\n",
              "      <td>13003.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000f6ccb0745a6a4b88665a16c9f078</td>\n",
              "      <td>PA</td>\n",
              "      <td>belem</td>\n",
              "      <td>66812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ef506c96320abeedfb894c34db06f478</td>\n",
              "      <td>4673.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0004aac84e0df4da2b147fca70cf8255</td>\n",
              "      <td>SP</td>\n",
              "      <td>sorocaba</td>\n",
              "      <td>18040</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70a12e78e608ac31179aea7f8422044b</td>\n",
              "      <td>25629.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        customer_id  ... product_id\n",
              "0  0000366f3b9a7992bf8c76cfdf3221e2  ...     7158.0\n",
              "1  0000b849f77a49e4a4ce2b2a4ca5be3f  ...    10466.0\n",
              "2  0000f46a3911fa3c0805444483337064  ...    13003.0\n",
              "3  0000f6ccb0745a6a4b88665a16c9f078  ...     4673.0\n",
              "4  0004aac84e0df4da2b147fca70cf8255  ...    25629.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3nw23s3LcM1",
        "colab_type": "code",
        "outputId": "2cf21709-49b4-455f-bdb3-2d3aa90704d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "##customer = prueba_clientes.drop(['product_id_y','product_id_x'], axis=1)\n",
        "customer.product_id = customer.product_id.fillna(0)\n",
        "customer.drop_duplicates()\n",
        "customer.count()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "customer_id                 112881\n",
              "customer_state              112881\n",
              "customer_city               112881\n",
              "customer_zip_code_prefix    112881\n",
              "is_churn                    112881\n",
              "seller_id                   112881\n",
              "product_id                  112881\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz4nl0fiyLhF",
        "colab_type": "code",
        "outputId": "d2f82fc1-833c-4fec-fdca-ed339b2fa51f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# codifico verticalmente \n",
        "customer['customer_state']= enconder.fit_transform(customer[\"customer_state\"])\n",
        "customer['customer_city']= enconder.fit_transform(customer[\"customer_city\"])\n",
        "customer['seller_id']= enconder.fit_transform( customer['seller_id'].astype('|S'))\n",
        "# Genero las variables de codificacion \n",
        "# se obtiene X y Y , además los datasets de entrenamiento y pruebas\n",
        "features = customer.drop(['customer_id','is_churn'], axis=1)\n",
        "labels = customer['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "\n",
        "features.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(112881, 5)\n",
            "(112881,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_state</th>\n",
              "      <th>customer_city</th>\n",
              "      <th>customer_zip_code_prefix</th>\n",
              "      <th>seller_id</th>\n",
              "      <th>product_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>655</td>\n",
              "      <td>7787</td>\n",
              "      <td>2644</td>\n",
              "      <td>7158.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "      <td>2594</td>\n",
              "      <td>6053</td>\n",
              "      <td>228</td>\n",
              "      <td>10466.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23</td>\n",
              "      <td>3520</td>\n",
              "      <td>88115</td>\n",
              "      <td>732</td>\n",
              "      <td>13003.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>448</td>\n",
              "      <td>66812</td>\n",
              "      <td>2891</td>\n",
              "      <td>4673.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25</td>\n",
              "      <td>3758</td>\n",
              "      <td>18040</td>\n",
              "      <td>1375</td>\n",
              "      <td>25629.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   customer_state  customer_city  ...  seller_id  product_id\n",
              "0              25            655  ...       2644      7158.0\n",
              "1              25           2594  ...        228     10466.0\n",
              "2              23           3520  ...        732     13003.0\n",
              "3              13            448  ...       2891      4673.0\n",
              "4              25           3758  ...       1375     25629.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbCqZteIy1H5",
        "colab_type": "code",
        "outputId": "26ca2221-efdc-411c-be61-524a186dff28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()\n",
        "#SVM()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inicia Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.98      0.91     18856\n",
            "         1.0       0.59      0.12      0.19      3721\n",
            "\n",
            "    accuracy                           0.84     22577\n",
            "   macro avg       0.72      0.55      0.55     22577\n",
            "weighted avg       0.81      0.84      0.79     22577\n",
            "\n",
            "[[18549   307]\n",
            " [ 3286   435]]\n",
            "0.8408557381405856\n",
            "inicia Regresión lineal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      1.00      0.91     18856\n",
            "         1.0       0.00      0.00      0.00      3721\n",
            "\n",
            "    accuracy                           0.84     22577\n",
            "   macro avg       0.42      0.50      0.46     22577\n",
            "weighted avg       0.70      0.84      0.76     22577\n",
            "\n",
            "[[18856     0]\n",
            " [ 3721     0]]\n",
            "0.8351862514948841\n",
            "inicia Arboles de decisión\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      1.00      0.91     18856\n",
            "         1.0       0.55      0.02      0.03      3721\n",
            "\n",
            "    accuracy                           0.84     22577\n",
            "   macro avg       0.69      0.51      0.47     22577\n",
            "weighted avg       0.79      0.84      0.77     22577\n",
            "\n",
            "[[18810    46]\n",
            " [ 3665    56]]\n",
            "0.8356291801390796\n",
            "inicia Gradient Boosting Classifier\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0905 21:29:17.412795 140153850288000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0905 21:29:17.468095 140153850288000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0905 21:29:17.476039 140153850288000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0905 21:29:17.552313 140153850288000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0905 21:29:17.561569 140153850288000 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      1.00      0.91     18856\n",
            "         1.0       0.90      0.01      0.03      3721\n",
            "\n",
            "    accuracy                           0.84     22577\n",
            "   macro avg       0.87      0.51      0.47     22577\n",
            "weighted avg       0.85      0.84      0.77     22577\n",
            "\n",
            "[[18850     6]\n",
            " [ 3666    55]]\n",
            "0.8373566018514418\n",
            "Inicia Deep Learning\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0905 21:29:17.695022 140153850288000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0905 21:29:17.717193 140153850288000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0905 21:29:17.722675 140153850288000 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 67728 samples, validate on 45153 samples\n",
            "Epoch 1/30\n",
            "67728/67728 [==============================] - 19s 285us/step - loss: 0.4551 - acc: 0.8336 - val_loss: 0.4512 - val_acc: 0.8321\n",
            "Epoch 2/30\n",
            "67728/67728 [==============================] - 15s 217us/step - loss: 0.4519 - acc: 0.8337 - val_loss: 0.4538 - val_acc: 0.8321\n",
            "Epoch 3/30\n",
            "67728/67728 [==============================] - 15s 220us/step - loss: 0.4507 - acc: 0.8337 - val_loss: 0.4508 - val_acc: 0.8321\n",
            "Epoch 4/30\n",
            "67728/67728 [==============================] - 15s 215us/step - loss: 0.4506 - acc: 0.8337 - val_loss: 0.4508 - val_acc: 0.8321\n",
            "Epoch 5/30\n",
            "67728/67728 [==============================] - 15s 215us/step - loss: 0.4499 - acc: 0.8337 - val_loss: 0.4530 - val_acc: 0.8321\n",
            "Epoch 6/30\n",
            "67728/67728 [==============================] - 15s 217us/step - loss: 0.4499 - acc: 0.8337 - val_loss: 0.4506 - val_acc: 0.8321\n",
            "Epoch 7/30\n",
            "67728/67728 [==============================] - 15s 215us/step - loss: 0.4498 - acc: 0.8337 - val_loss: 0.4511 - val_acc: 0.8321\n",
            "Epoch 8/30\n",
            "67728/67728 [==============================] - 15s 217us/step - loss: 0.4499 - acc: 0.8337 - val_loss: 0.4509 - val_acc: 0.8321\n",
            "Epoch 9/30\n",
            "36780/67728 [===============>..............] - ETA: 5s - loss: 0.4492 - acc: 0.8337"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-b55f9288a133>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0marbolDecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgradientBoost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mredesNeuronales\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#SVM()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-235bda33f3f7>\u001b[0m in \u001b[0;36mredesNeuronales\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m# compilar el modelo utilizando la precisión para medir el rendimiento del modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mmodelo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m   \u001b[0mresultado\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping_monitor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu43U7dFchuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prueba 3 -  (City - Seller - Producto) Sin state\n",
        "\n",
        " \n",
        "print(summary.median())\n",
        "\n",
        "## Marco los churn\n",
        "summary['is_churn'] = np.where( (summary['frequency']<1) & (summary['T']>400) & (summary['recency']<1) & (summary['recency']<0.000044), 1, 0) \n",
        "prueba_clientes = pd.merge(datos_clientes,summary[['is_churn']],on='customer_id', how='left')\n",
        "## traigo los vendedores\n",
        "prueba_clientes = pd.merge(prueba_clientes,datos_facturacion[['customer_id','seller_id']].drop_duplicates(),on='customer_id', how='left')\n",
        "## Traigo los productos\n",
        "\n",
        "# Completo la información de los churn con 0\n",
        "prueba_clientes['is_churn'].fillna(0, inplace=True)\n",
        "\n",
        "# Completo la información de los vendedores con un vendedor default\n",
        "prueba_clientes['seller_id'].fillna(0, inplace=True)\n",
        "#prueba_clientes['product_id'].fillna(0, inplace=True)\n",
        "\n",
        "# imprimio numero de clientes, cuantos son churn y que % es del total \n",
        "print(prueba_clientes.count())\n",
        "prueba_clientes.groupby('is_churn').count()\n",
        "prueba_clientes['is_churn'].mean()\n",
        "\n",
        "\n",
        "\n",
        "# codificacione de las variables\n",
        "enconder = LabelEncoder()\n",
        "# obtengo un dataset sin la información las columnas a transformar\n",
        "\n",
        "\n",
        "url2 = 'https://github.com/masdatascience/TFM-AI/blob/master/data_model_completo.xlsx?raw=true'\n",
        "datos_fac = pd.ExcelFile(url2)\n",
        "datos_fac_prod = pd.read_excel(datos_fac, sheet_name='fac_txn')\n",
        "datos_fac_prod= datos_fac_prod[['customer_id','product_id']]\n",
        "datos_fac_prod['product_id']= enconder.fit_transform( datos_fac_prod['product_id'])\n",
        "prueba_clientes = pd.merge(prueba_clientes,datos_fac_prod.drop_duplicates(),on='customer_id', how='left')\n",
        "#Obtengo el dataset de trabajo     \n",
        "customer = prueba_clientes.copy()\n",
        "\n",
        "customer.head()\n",
        "#customer = prueba_clientes.drop(['product_id_y','product_id_x'], axis=1)\n",
        "customer.product_id = customer.product_id.fillna(0)\n",
        "customer.drop_duplicates()\n",
        "customer.count()\n",
        "\n",
        "\n",
        "# Sin state\n",
        "#customer['customer_state']= enconder.fit_transform(customer[\"customer_state\"])\n",
        "#customer= customer.drop(['customer_state','customer_zip_code_prefix'])\n",
        "\n",
        "# codifico verticalmente \n",
        "customer['customer_state']= enconder.fit_transform(customer[\"customer_state\"])\n",
        "customer['seller_id']= enconder.fit_transform( customer['seller_id'].astype('|S'))\n",
        "# Genero las variables de codificacion \n",
        "# se obtiene X y Y , además los datasets de entrenamiento y pruebas\n",
        "features = customer.drop(['customer_id','is_churn','customer_city','customer_zip_code_prefix'], axis=1)\n",
        "labels = customer['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "\n",
        "features.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBESYS5ScpXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()\n",
        "#SVM()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUyJopMsMp3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prueba 5 -  (City - Seller - Producto) Sin state\n",
        "\n",
        " \n",
        "print(summary.median())\n",
        "\n",
        "## Marco los churn\n",
        "summary['is_churn'] = np.where( (summary['frequency']<1) & (summary['T']>400) & (summary['recency']<1) & (summary['recency']<0.000044), 1, 0) \n",
        "prueba_clientes = pd.merge(datos_clientes,summary[['is_churn']],on='customer_id', how='left')\n",
        "## traigo los vendedores\n",
        "prueba_clientes = pd.merge(prueba_clientes,datos_facturacion[['customer_id','seller_id']].drop_duplicates(),on='customer_id', how='left')\n",
        "## Traigo los productos\n",
        "\n",
        "# Completo la información de los churn con 0\n",
        "prueba_clientes['is_churn'].fillna(0, inplace=True)\n",
        "\n",
        "# Completo la información de los vendedores con un vendedor default\n",
        "prueba_clientes['seller_id'].fillna(0, inplace=True)\n",
        "#prueba_clientes['product_id'].fillna(0, inplace=True)\n",
        "\n",
        "# imprimio numero de clientes, cuantos son churn y que % es del total \n",
        "print(prueba_clientes.count())\n",
        "prueba_clientes.groupby('is_churn').count()\n",
        "prueba_clientes['is_churn'].mean()\n",
        "\n",
        "\n",
        "\n",
        "# codificacione de las variables\n",
        "enconder = LabelEncoder()\n",
        "# obtengo un dataset sin la información las columnas a transformar\n",
        "\n",
        "\n",
        "url2 = 'https://github.com/masdatascience/TFM-AI/blob/master/data_model_completo.xlsx?raw=true'\n",
        "datos_fac = pd.ExcelFile(url2)\n",
        "datos_fac_prod = pd.read_excel(datos_fac, sheet_name='fac_txn')\n",
        "datos_fac_prod= datos_fac_prod[['customer_id','product_id']]\n",
        "datos_fac_prod['product_id']= enconder.fit_transform( datos_fac_prod['product_id'])\n",
        "prueba_clientes = pd.merge(prueba_clientes,datos_fac_prod.drop_duplicates(),on='customer_id', how='left')\n",
        "#Obtengo el dataset de trabajo     \n",
        "customer = prueba_clientes.copy()\n",
        "\n",
        "customer.head()\n",
        "#customer = prueba_clientes.drop(['product_id_y','product_id_x'], axis=1)\n",
        "customer.product_id = customer.product_id.fillna(0)\n",
        "customer.drop_duplicates()\n",
        "customer.count()\n",
        "\n",
        "\n",
        "# Sin state\n",
        "#customer['customer_state']= enconder.fit_transform(customer[\"customer_state\"])\n",
        "#customer= customer.drop(['customer_state','customer_zip_code_prefix'])\n",
        "\n",
        "# codifico verticalmente \n",
        "customer['customer_city']= enconder.fit_transform(customer[\"customer_city\"])\n",
        "customer['seller_id']= enconder.fit_transform( customer['seller_id'].astype('|S'))\n",
        "# Genero las variables de codificacion \n",
        "# se obtiene X y Y , además los datasets de entrenamiento y pruebas\n",
        "features = customer.drop(['customer_id','is_churn','customer_state','customer_zip_code_prefix'], axis=1)\n",
        "labels = customer['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "\n",
        "features.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txbb8vT9M7RI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()\n",
        "#SVM()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgulr5dnPYRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prueba 4 -  (City - Seller - Producto) Sin prefix\n",
        "\n",
        " \n",
        "print(summary.median())\n",
        "\n",
        "## Marco los churn\n",
        "summary['is_churn'] = np.where( (summary['frequency']<1) & (summary['T']>400) & (summary['recency']<1) & (summary['recency']<0.000044), 1, 0) \n",
        "prueba_clientes = pd.merge(datos_clientes,summary[['is_churn']],on='customer_id', how='left')\n",
        "## traigo los vendedores\n",
        "prueba_clientes = pd.merge(prueba_clientes,datos_facturacion[['customer_id','seller_id']].drop_duplicates(),on='customer_id', how='left')\n",
        "## Traigo los productos\n",
        "\n",
        "# Completo la información de los churn con 0\n",
        "prueba_clientes['is_churn'].fillna(0, inplace=True)\n",
        "\n",
        "# Completo la información de los vendedores con un vendedor default\n",
        "prueba_clientes['seller_id'].fillna(0, inplace=True)\n",
        "#prueba_clientes['product_id'].fillna(0, inplace=True)\n",
        "\n",
        "# imprimio numero de clientes, cuantos son churn y que % es del total \n",
        "print(prueba_clientes.count())\n",
        "prueba_clientes.groupby('is_churn').count()\n",
        "prueba_clientes['is_churn'].mean()\n",
        "\n",
        "\n",
        "\n",
        "# codificacione de las variables\n",
        "enconder = LabelEncoder()\n",
        "# obtengo un dataset sin la información las columnas a transformar\n",
        "\n",
        "\n",
        "url2 = 'https://github.com/masdatascience/TFM-AI/blob/master/data_model_completo.xlsx?raw=true'\n",
        "datos_fac = pd.ExcelFile(url2)\n",
        "datos_fac_prod = pd.read_excel(datos_fac, sheet_name='fac_txn')\n",
        "datos_fac_prod= datos_fac_prod[['customer_id','product_id']]\n",
        "datos_fac_prod['product_id']= enconder.fit_transform( datos_fac_prod['product_id'])\n",
        "prueba_clientes = pd.merge(prueba_clientes,datos_fac_prod.drop_duplicates(),on='customer_id', how='left')\n",
        "#Obtengo el dataset de trabajo     \n",
        "customer = prueba_clientes.copy()\n",
        "customer.head()\n",
        "\n",
        "#customer = prueba_clientes.drop(['product_id_y','product_id_x'], axis=1)\n",
        "customer.product_id = customer.product_id.fillna(0)\n",
        "customer.drop_duplicates()\n",
        "customer.count()\n",
        "\n",
        "# codifico verticalmente \n",
        "customer['customer_state']= enconder.fit_transform(customer[\"customer_state\"])\n",
        "\n",
        "customer['customer_city']= enconder.fit_transform(customer[\"customer_city\"])\n",
        "customer['seller_id']= enconder.fit_transform( customer['seller_id'].astype('|S'))\n",
        "# Genero las variables de codificacion \n",
        "# se obtiene X y Y , además los datasets de entrenamiento y pruebas\n",
        "features = customer.drop(['customer_id','is_churn','customer_zip_code_prefix'], axis=1)\n",
        "labels = customer['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "\n",
        "features.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xKL4mypQZE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()\n",
        "#SVM()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyi6IGFoP2KV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prueba 6 -  (City - Seller ) Sin prefix, estado,producto\n",
        "\n",
        " \n",
        "print(summary.median())\n",
        "\n",
        "## Marco los churn\n",
        "summary['is_churn'] = np.where( (summary['frequency']<1) & (summary['T']>400) & (summary['recency']<1) & (summary['recency']<0.000044), 1, 0) \n",
        "prueba_clientes = pd.merge(datos_clientes,summary[['is_churn']],on='customer_id', how='left')\n",
        "## traigo los vendedores\n",
        "prueba_clientes = pd.merge(prueba_clientes,datos_facturacion[['customer_id','seller_id']].drop_duplicates(),on='customer_id', how='left')\n",
        "## Traigo los productos\n",
        "\n",
        "# Completo la información de los churn con 0\n",
        "prueba_clientes['is_churn'].fillna(0, inplace=True)\n",
        "\n",
        "# Completo la información de los vendedores con un vendedor default\n",
        "prueba_clientes['seller_id'].fillna(0, inplace=True)\n",
        "#prueba_clientes['product_id'].fillna(0, inplace=True)\n",
        "\n",
        "# imprimio numero de clientes, cuantos son churn y que % es del total \n",
        "print(prueba_clientes.count())\n",
        "prueba_clientes.groupby('is_churn').count()\n",
        "prueba_clientes['is_churn'].mean()\n",
        "\n",
        "\n",
        "\n",
        "# codificacione de las variables\n",
        "enconder = LabelEncoder()\n",
        "# obtengo un dataset sin la información las columnas a transformar\n",
        "\n",
        "\n",
        "#url2 = 'https://github.com/masdatascience/TFM-AI/blob/master/data_model_completo.xlsx?raw=true'\n",
        "#datos_fac = pd.ExcelFile(url2)\n",
        "#datos_fac_prod = pd.read_excel(datos_fac, sheet_name='fac_txn')\n",
        "#datos_fac_prod= datos_fac_prod[['customer_id','product_id']]\n",
        "#datos_fac_prod['product_id']= enconder.fit_transform( datos_fac_prod['product_id'])\n",
        "#prueba_clientes = pd.merge(prueba_clientes,datos_fac_prod.drop_duplicates(),on='customer_id', how='left')\n",
        "#Obtengo el dataset de trabajo     \n",
        "customer = prueba_clientes.copy()\n",
        "customer.head()\n",
        "\n",
        "#customer = prueba_clientes.drop(['product_id_y','product_id_x'], axis=1)\n",
        "#customer.product_id = customer.product_id.fillna(0)\n",
        "customer.drop_duplicates()\n",
        "customer.count()\n",
        "\n",
        "\n",
        "# Sin zip code\n",
        " \n",
        "customer['customer_state']= enconder.fit_transform(customer[\"customer_state\"])\n",
        "\n",
        "# codifico verticalmente \n",
        "#\n",
        "customer['customer_city']= enconder.fit_transform(customer[\"customer_city\"])\n",
        "customer['seller_id']= enconder.fit_transform( customer['seller_id'].astype('|S'))\n",
        "# Genero las variables de codificacion \n",
        "# se obtiene X y Y , además los datasets de entrenamiento y pruebas\n",
        "features = customer.drop(['customer_id','is_churn','customer_zip_code_prefix','customer_state'], axis=1)\n",
        "labels = customer['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "\n",
        "features.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB0d0FN9QZ5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()\n",
        "SVM()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TET6vdgvQj0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prueba 7 -  (City - Seller ) Sin estado,prefix, seller\n",
        "\n",
        " \n",
        "print(summary.median())\n",
        "\n",
        "## Marco los churn\n",
        "summary['is_churn'] = np.where( (summary['frequency']<1) & (summary['T']>400) & (summary['recency']<1) & (summary['recency']<0.000044), 1, 0) \n",
        "prueba_clientes = pd.merge(datos_clientes,summary[['is_churn']],on='customer_id', how='left')\n",
        "## traigo los vendedores\n",
        "#prueba_clientes = pd.merge(prueba_clientes,datos_facturacion[['customer_id','seller_id']].drop_duplicates(),on='customer_id', how='left')\n",
        "## Traigo los productos\n",
        "\n",
        "# Completo la información de los churn con 0\n",
        "prueba_clientes['is_churn'].fillna(0, inplace=True)\n",
        "\n",
        "# Completo la información de los vendedores con un vendedor default\n",
        "#prueba_clientes['seller_id'].fillna(0, inplace=True)\n",
        "#prueba_clientes['product_id'].fillna(0, inplace=True)\n",
        "\n",
        "# imprimio numero de clientes, cuantos son churn y que % es del total \n",
        "print(prueba_clientes.count())\n",
        "prueba_clientes.groupby('is_churn').count()\n",
        "prueba_clientes['is_churn'].mean()\n",
        "\n",
        "\n",
        "\n",
        "# codificacione de las variables\n",
        "enconder = LabelEncoder()\n",
        "# obtengo un dataset sin la información las columnas a transformar\n",
        "\n",
        "\n",
        "url2 = 'https://github.com/masdatascience/TFM-AI/blob/master/data_model_completo.xlsx?raw=true'\n",
        "datos_fac = pd.ExcelFile(url2)\n",
        "datos_fac_prod = pd.read_excel(datos_fac, sheet_name='fac_txn')\n",
        "datos_fac_prod= datos_fac_prod[['customer_id','product_id']]\n",
        "datos_fac_prod['product_id']= enconder.fit_transform( datos_fac_prod['product_id'])\n",
        "prueba_clientes = pd.merge(prueba_clientes,datos_fac_prod.drop_duplicates(),on='customer_id', how='left')\n",
        "#Obtengo el dataset de trabajo     \n",
        "customer = prueba_clientes.copy()\n",
        "customer.head()\n",
        "\n",
        "#customer = prueba_clientes.drop(['product_id_y','product_id_x'], axis=1)\n",
        "customer.product_id = customer.product_id.fillna(0)\n",
        "customer.drop_duplicates()\n",
        "customer.count()\n",
        "\n",
        "\n",
        "# Sin zip code\n",
        "#customer= customer.drop['customer_zip_code_prefix','customer_state'] \n",
        "#ustomer['customer_state']= enconder.fit_transform(customer[\"customer_state\"])\n",
        "\n",
        "# codifico verticalmente \n",
        "#\n",
        "customer['customer_city']= enconder.fit_transform(customer[\"customer_city\"])\n",
        "#customer['seller_id']= enconder.fit_transform( customer['seller_id'].astype('|S'))\n",
        "# Genero las variables de codificacion \n",
        "# se obtiene X y Y , además los datasets de entrenamiento y pruebas\n",
        "features = customer.drop(['customer_id','is_churn','customer_zip_code_prefix','customer_state'], axis=1)\n",
        "labels = customer['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "\n",
        "features.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMlG29e4RFYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()\n",
        "#SVM()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp4iKtcTY8uL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prueba 8 -  Dinero\n",
        "\n",
        " \n",
        "print(summary.median())\n",
        "\n",
        "## Marco los churn\n",
        "summary['is_churn'] = np.where( (summary['frequency']<1) & (summary['T']>400) & (summary['recency']<1) & (summary['recency']<0.000044), 1, 0) \n",
        "prueba_clientes = pd.merge(datos_clientes,summary[['is_churn']],on='customer_id', how='left')\n",
        "## traigo los vendedores\n",
        "prueba_clientes = pd.merge(prueba_clientes,datos_facturacion[['customer_id','seller_id']].drop_duplicates(),on='customer_id', how='left')\n",
        "## Traigo los productos\n",
        "\n",
        "# Completo la información de los churn con 0\n",
        "prueba_clientes['is_churn'].fillna(0, inplace=True)\n",
        "\n",
        "# Completo la información de los vendedores con un vendedor default\n",
        "prueba_clientes['seller_id'].fillna(0, inplace=True)\n",
        "#prueba_clientes['product_id'].fillna(0, inplace=True)\n",
        "\n",
        "# imprimio numero de clientes, cuantos son churn y que % es del total \n",
        "print(prueba_clientes.count())\n",
        "prueba_clientes.groupby('is_churn').count()\n",
        "prueba_clientes['is_churn'].mean()\n",
        "\n",
        "\n",
        "\n",
        "# codificacione de las variables\n",
        "enconder = LabelEncoder()\n",
        "# obtengo un dataset sin la información las columnas a transformar\n",
        " \n",
        "url2 = 'https://github.com/masdatascience/TFM-AI/blob/master/data_model_completo.xlsx?raw=true'\n",
        "datos_fac = pd.ExcelFile(url2)\n",
        "datos_fac_prod = pd.read_excel(datos_fac, sheet_name='fac_txn')\n",
        "datos_fac_prod= datos_fac_prod[['customer_id','product_id','total_value']]\n",
        "datos_fac_prod['product_id']= enconder.fit_transform( datos_fac_prod['product_id'])\n",
        "prueba_clientes = pd.merge(prueba_clientes,datos_fac_prod.drop_duplicates(),on='customer_id', how='left')\n",
        "#Obtengo el dataset de trabajo     \n",
        "customer = prueba_clientes.copy()\n",
        "customer.head()\n",
        "\n",
        "customer.product_id = customer.product_id.fillna(0)\n",
        "customer.total_value = customer.total_value.fillna(0)\n",
        "customer.drop_duplicates()\n",
        "customer.count() \n",
        " # codifico verticalmente \n",
        "customer['customer_state']= enconder.fit_transform(customer[\"customer_state\"])\n",
        "customer['customer_city']= enconder.fit_transform(customer[\"customer_city\"])\n",
        "customer['seller_id']= enconder.fit_transform( customer['seller_id'].astype('|S'))\n",
        "# Genero las variables de codificacion \n",
        "# se obtiene X y Y , además los datasets de entrenamiento y pruebas\n",
        "features = customer.drop(['customer_id','is_churn'], axis=1)\n",
        "labels = customer['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "\n",
        "features.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j0ZBCUxaBnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()\n",
        "#SVM()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8r_nq1eFJPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "01352926-3786-4b16-8b25-02ba247e414b"
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.3.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.21.3)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.24.2)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.1)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5fyaon93HqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxyuYSn6FRS-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52931525-3d36-4862-a14e-68bc6219b304"
      },
      "source": [
        "## Marco los churn\n",
        "summary['is_churn'] = np.where( (summary['frequency']<1) & (summary['T']>400) & (summary['recency']<1) & (summary['recency']<0.000044), 1, 0) \n",
        "prueba_clientes = pd.merge(datos_clientes,summary[['is_churn']],on='customer_id', how='left')\n",
        "## traigo los vendedores\n",
        "prueba_clientes = pd.merge(prueba_clientes,datos_facturacion[['customer_id','seller_id']].drop_duplicates(),on='customer_id', how='left')\n",
        "\n",
        "# Completo la información de los churn con 0\n",
        "prueba_clientes['is_churn'].fillna(0, inplace=True)\n",
        "# Completo la información de los vendedores con un vendedor default\n",
        "prueba_clientes['seller_id'].fillna(0, inplace=True)\n",
        "\n",
        "# set up X and y\n",
        "X = prueba_clientes['seller_id']\n",
        "y = prueba_clientes.drop('seller_id', axis = 1)\n",
        "\n",
        "\n",
        "ce_hash = ce.HashingEncoder(cols = ['seller_id'])\n",
        "ce_hash.fit_transform(X, y)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col_0</th>\n",
              "      <th>col_1</th>\n",
              "      <th>col_2</th>\n",
              "      <th>col_3</th>\n",
              "      <th>col_4</th>\n",
              "      <th>col_5</th>\n",
              "      <th>col_6</th>\n",
              "      <th>col_7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100202</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100203</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100204</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100205</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100206</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100207</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100208</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100209</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100210</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100211</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100212</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100213</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100214</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100215</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100216</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100217</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100218</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100219</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100220</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100221</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100222</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100223</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100224</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100225</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100226</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100227</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100228</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100229</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100230</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100231</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100232 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        col_0  col_1  col_2  col_3  col_4  col_5  col_6  col_7\n",
              "0           0      0      0      0      0      0      0      1\n",
              "1           0      0      0      0      0      0      0      1\n",
              "2           0      0      0      0      1      0      0      0\n",
              "3           1      0      0      0      0      0      0      0\n",
              "4           1      0      0      0      0      0      0      0\n",
              "5           0      0      0      0      1      0      0      0\n",
              "6           0      0      0      0      0      0      1      0\n",
              "7           0      0      0      0      1      0      0      0\n",
              "8           0      0      0      1      0      0      0      0\n",
              "9           0      0      1      0      0      0      0      0\n",
              "10          0      0      0      0      1      0      0      0\n",
              "11          0      0      1      0      0      0      0      0\n",
              "12          1      0      0      0      0      0      0      0\n",
              "13          0      0      0      1      0      0      0      0\n",
              "14          0      0      0      0      0      0      0      1\n",
              "15          0      0      0      1      0      0      0      0\n",
              "16          0      0      0      0      1      0      0      0\n",
              "17          1      0      0      0      0      0      0      0\n",
              "18          0      0      0      0      0      0      0      1\n",
              "19          0      0      0      0      1      0      0      0\n",
              "20          0      0      0      0      0      1      0      0\n",
              "21          1      0      0      0      0      0      0      0\n",
              "22          0      0      0      0      0      0      0      1\n",
              "23          0      0      0      0      0      1      0      0\n",
              "24          0      0      0      1      0      0      0      0\n",
              "25          1      0      0      0      0      0      0      0\n",
              "26          0      0      0      0      0      0      1      0\n",
              "27          0      1      0      0      0      0      0      0\n",
              "28          0      0      0      0      0      0      0      1\n",
              "29          0      1      0      0      0      0      0      0\n",
              "...       ...    ...    ...    ...    ...    ...    ...    ...\n",
              "100202      0      0      1      0      0      0      0      0\n",
              "100203      0      0      0      1      0      0      0      0\n",
              "100204      0      0      0      0      0      1      0      0\n",
              "100205      0      0      0      0      0      0      0      1\n",
              "100206      0      0      1      0      0      0      0      0\n",
              "100207      0      0      0      0      1      0      0      0\n",
              "100208      0      0      0      0      0      0      1      0\n",
              "100209      0      0      0      0      0      0      1      0\n",
              "100210      0      0      0      1      0      0      0      0\n",
              "100211      0      0      0      0      0      1      0      0\n",
              "100212      0      0      0      1      0      0      0      0\n",
              "100213      0      0      1      0      0      0      0      0\n",
              "100214      0      0      0      0      0      0      0      1\n",
              "100215      0      0      0      0      0      0      1      0\n",
              "100216      0      0      1      0      0      0      0      0\n",
              "100217      0      0      0      1      0      0      0      0\n",
              "100218      0      0      0      0      0      0      0      1\n",
              "100219      1      0      0      0      0      0      0      0\n",
              "100220      0      0      1      0      0      0      0      0\n",
              "100221      0      1      0      0      0      0      0      0\n",
              "100222      1      0      0      0      0      0      0      0\n",
              "100223      0      0      0      1      0      0      0      0\n",
              "100224      0      0      0      1      0      0      0      0\n",
              "100225      0      0      0      0      0      0      1      0\n",
              "100226      0      0      1      0      0      0      0      0\n",
              "100227      0      0      0      0      0      1      0      0\n",
              "100228      0      0      0      0      0      0      0      1\n",
              "100229      0      0      0      1      0      0      0      0\n",
              "100230      0      0      1      0      0      0      0      0\n",
              "100231      0      0      1      0      0      0      0      0\n",
              "\n",
              "[100232 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO1Ae0DdIPhT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "fb256f0c-9130-43e0-bfd4-c38b2a16c3b5"
      },
      "source": [
        "print(ce_hash)\n",
        "print(type(ce_hash))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HashingEncoder(cols=['seller_id'], drop_invariant=False, hash_method='md5',\n",
            "               n_components=8, return_df=True, verbose=0)\n",
            "<class 'category_encoders.hashing.HashingEncoder'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umNGZGpxG_ad",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "450e9446-f9d1-4b03-cac4-a628d671e7b1"
      },
      "source": [
        "# codificacione de las variables\n",
        "enconder = LabelEncoder()\n",
        "# obtengo un dataset sin la información las columnas a transformar\n",
        " \n",
        "url2 = 'https://github.com/masdatascience/TFM-AI/blob/master/data_model_completo.xlsx?raw=true'\n",
        "datos_fac = pd.ExcelFile(url2)\n",
        "datos_fac_prod = pd.read_excel(datos_fac, sheet_name='fac_txn')\n",
        "datos_fac_prod= datos_fac_prod[['customer_id','product_id','total_value']]\n",
        "datos_fac_prod['product_id']= enconder.fit_transform( datos_fac_prod['product_id'])\n",
        "prueba_clientes = pd.merge(prueba_clientes,datos_fac_prod.drop_duplicates(),on='customer_id', how='left')\n",
        "#Obtengo el dataset de trabajo     \n",
        "customer = prueba_clientes.copy()\n",
        "customer.head()\n",
        "\n",
        "customer.product_id = customer.product_id.fillna(0)\n",
        "customer.total_value = customer.total_value.fillna(0)\n",
        "customer.drop_duplicates()\n",
        "customer.count() \n",
        " # codifico verticalmente \n",
        "customer['customer_state']= enconder.fit_transform(customer[\"customer_state\"])\n",
        "customer['customer_city']= enconder.fit_transform(customer[\"customer_city\"])\n",
        "customer['seller_id']= enconder.fit_transform( customer['seller_id'].astype('|S'))\n",
        "# Genero las variables de codificacion \n",
        "# se obtiene X y Y , además los datasets de entrenamiento y pruebas\n",
        "features = customer.drop(['customer_id','is_churn'], axis=1)\n",
        "labels = customer['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "\n",
        "features.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(113162, 6)\n",
            "(113162,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_state</th>\n",
              "      <th>customer_city</th>\n",
              "      <th>customer_zip_code_prefix</th>\n",
              "      <th>seller_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>total_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>655</td>\n",
              "      <td>7787</td>\n",
              "      <td>2644</td>\n",
              "      <td>7158.0</td>\n",
              "      <td>14190.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "      <td>2594</td>\n",
              "      <td>6053</td>\n",
              "      <td>228</td>\n",
              "      <td>10466.0</td>\n",
              "      <td>2719.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23</td>\n",
              "      <td>3520</td>\n",
              "      <td>88115</td>\n",
              "      <td>732</td>\n",
              "      <td>13003.0</td>\n",
              "      <td>8622.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>448</td>\n",
              "      <td>66812</td>\n",
              "      <td>2891</td>\n",
              "      <td>4673.0</td>\n",
              "      <td>4362.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25</td>\n",
              "      <td>3758</td>\n",
              "      <td>18040</td>\n",
              "      <td>1375</td>\n",
              "      <td>25629.0</td>\n",
              "      <td>19689.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   customer_state  customer_city  ...  product_id  total_value\n",
              "0              25            655  ...      7158.0      14190.0\n",
              "1              25           2594  ...     10466.0       2719.0\n",
              "2              23           3520  ...     13003.0       8622.0\n",
              "3              13            448  ...      4673.0       4362.0\n",
              "4              25           3758  ...     25629.0      19689.0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e89IE03rNgBX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "outputId": "8170d875-edf6-4587-ab6c-0fb60f2f7b90"
      },
      "source": [
        "url2 = 'https://github.com/masdatascience/TFM-AI/blob/master/data_model_completo_2.xlsx?raw=true'\n",
        "datos_fac = pd.ExcelFile(url2)\n",
        "datos_fac = pd.read_excel(datos_fac, sheet_name='fac_txn')\n",
        "datos_fac_prod = datos_fac.copy()\n",
        "datos_fac_prod.sort_values([\"order_id\", \"total_value\"], axis=0, ascending=False, inplace=True)\n",
        "datos_fac_prod.drop_duplicates('order_id',keep='first',inplace=True)\n",
        "#items\n",
        "datos_fac_prod['product_id']= enconder.fit_transform(datos_fac_prod[\"product_id\"])\n",
        "datos_fac_prod['order_status']= enconder.fit_transform(datos_fac_prod[\"order_status\"])\n",
        "datos_fac_prod['seller_id']= enconder.fit_transform( datos_fac_prod['seller_id'].astype('|S'))\n",
        "datos_fac_prod.head(10)\n",
        "datos_fac_prod = pd.merge(datos_fac_prod,summary[['is_churn']],on='customer_id', how='left')\n",
        "datos_fac_prod=datos_fac_prod.drop(['order_id','order_item_id','customer_id'], axis=1)\n",
        "datos_fac_prod=datos_fac_prod.drop(['shipping_limit_date','order_purchase_timestamp','order_approved_at','order_delivered_carrier_date','order_delivered_customer_date','order_estimated_delivery_date'], axis=1)\n",
        "datos_fac_prod.head()# Completo la información de los churn con 0\n",
        "datos_fac_prod['is_churn'].fillna(0, inplace=True)\n",
        "datos_fac_prod = datos_fac_prod.fillna(0)\n",
        "print(datos_fac_prod.is_churn.mean())\n",
        "features = datos_fac_prod.drop(['is_churn'], axis=1)\n",
        "labels = datos_fac_prod['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "print(datos_fac_prod.isnull().sum())\n",
        "features.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.17763971378184987\n",
            "(98666, 13)\n",
            "(98666,)\n",
            "product_id                  0\n",
            "customer_zip_code_prefix    0\n",
            "seller_id                   0\n",
            "price                       0\n",
            "freight_value               0\n",
            "total_value                 0\n",
            "credit_card                 0\n",
            "debit_card                  0\n",
            "boleto                      0\n",
            "voucher                     0\n",
            "not_defined                 0\n",
            "num_txn                     0\n",
            "order_status                0\n",
            "is_churn                    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>customer_zip_code_prefix</th>\n",
              "      <th>seller_id</th>\n",
              "      <th>price</th>\n",
              "      <th>freight_value</th>\n",
              "      <th>total_value</th>\n",
              "      <th>credit_card</th>\n",
              "      <th>debit_card</th>\n",
              "      <th>boleto</th>\n",
              "      <th>voucher</th>\n",
              "      <th>not_defined</th>\n",
              "      <th>num_txn</th>\n",
              "      <th>order_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6686</td>\n",
              "      <td>18605</td>\n",
              "      <td>2986</td>\n",
              "      <td>4300</td>\n",
              "      <td>1279</td>\n",
              "      <td>5579</td>\n",
              "      <td>5579.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19421</td>\n",
              "      <td>13289</td>\n",
              "      <td>507</td>\n",
              "      <td>5599</td>\n",
              "      <td>872</td>\n",
              "      <td>6471</td>\n",
              "      <td>6471.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14352</td>\n",
              "      <td>4039</td>\n",
              "      <td>2357</td>\n",
              "      <td>9990</td>\n",
              "      <td>1695</td>\n",
              "      <td>11685</td>\n",
              "      <td>11685.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6409</td>\n",
              "      <td>81690</td>\n",
              "      <td>2938</td>\n",
              "      <td>35000</td>\n",
              "      <td>3653</td>\n",
              "      <td>38653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38653.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9398</td>\n",
              "      <td>65077</td>\n",
              "      <td>2211</td>\n",
              "      <td>29999</td>\n",
              "      <td>4341</td>\n",
              "      <td>34340</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>34340.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   product_id  customer_zip_code_prefix  ...  num_txn  order_status\n",
              "0        6686                     18605  ...      1.0             2\n",
              "1       19421                     13289  ...      1.0             2\n",
              "2       14352                      4039  ...      1.0             2\n",
              "3        6409                     81690  ...      1.0             2\n",
              "4        9398                     65077  ...      1.0             2\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdMTSSzaUOK3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5126d22e-806b-4b3c-9137-9ae96603d5b8"
      },
      "source": [
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()\n",
        "#SVM()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inicia Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.99      0.92     16188\n",
            "           1       0.81      0.27      0.41      3546\n",
            "\n",
            "    accuracy                           0.86     19734\n",
            "   macro avg       0.84      0.63      0.66     19734\n",
            "weighted avg       0.85      0.86      0.83     19734\n",
            "\n",
            "[[15961   227]\n",
            " [ 2572   974]]\n",
            "0.8581635755548799\n",
            "inicia Regresión lineal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16188\n",
            "           1       0.00      0.00      0.00      3546\n",
            "\n",
            "    accuracy                           0.82     19734\n",
            "   macro avg       0.41      0.50      0.45     19734\n",
            "weighted avg       0.67      0.82      0.74     19734\n",
            "\n",
            "[[16188     0]\n",
            " [ 3546     0]]\n",
            "0.8203101246579507\n",
            "inicia Arboles de decisión\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16188\n",
            "           1       0.51      0.01      0.02      3546\n",
            "\n",
            "    accuracy                           0.82     19734\n",
            "   macro avg       0.67      0.50      0.46     19734\n",
            "weighted avg       0.77      0.82      0.74     19734\n",
            "\n",
            "[[16150    38]\n",
            " [ 3506    40]]\n",
            "0.8204114725853856\n",
            "inicia Gradient Boosting Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91     16188\n",
            "           1       0.92      0.08      0.15      3546\n",
            "\n",
            "    accuracy                           0.83     19734\n",
            "   macro avg       0.88      0.54      0.53     19734\n",
            "weighted avg       0.85      0.83      0.77     19734\n",
            "\n",
            "[[16162    26]\n",
            " [ 3253   293]]\n",
            "0.8338400729705078\n",
            "Inicia Deep Learning\n",
            "Train on 59199 samples, validate on 39467 samples\n",
            "Epoch 1/30\n",
            "59199/59199 [==============================] - 14s 228us/step - loss: 0.4755 - acc: 0.8197 - val_loss: 0.4623 - val_acc: 0.8251\n",
            "Epoch 2/30\n",
            "59199/59199 [==============================] - 13s 217us/step - loss: 0.4706 - acc: 0.8205 - val_loss: 0.4593 - val_acc: 0.8251\n",
            "Epoch 3/30\n",
            "59199/59199 [==============================] - 13s 215us/step - loss: 0.4692 - acc: 0.8205 - val_loss: 0.4589 - val_acc: 0.8251\n",
            "Epoch 4/30\n",
            "59199/59199 [==============================] - 13s 216us/step - loss: 0.4689 - acc: 0.8205 - val_loss: 0.4608 - val_acc: 0.8251\n",
            "Epoch 5/30\n",
            "59199/59199 [==============================] - 13s 217us/step - loss: 0.4680 - acc: 0.8205 - val_loss: 0.4579 - val_acc: 0.8251\n",
            "Epoch 6/30\n",
            "59199/59199 [==============================] - 13s 218us/step - loss: 0.4662 - acc: 0.8205 - val_loss: 0.4571 - val_acc: 0.8251\n",
            "Epoch 7/30\n",
            "59199/59199 [==============================] - 13s 215us/step - loss: 0.4656 - acc: 0.8205 - val_loss: 0.4557 - val_acc: 0.8251\n",
            "Epoch 8/30\n",
            "59199/59199 [==============================] - 13s 217us/step - loss: 0.4644 - acc: 0.8205 - val_loss: 0.4542 - val_acc: 0.8251\n",
            "Epoch 9/30\n",
            "59199/59199 [==============================] - 13s 216us/step - loss: 0.4632 - acc: 0.8205 - val_loss: 0.4535 - val_acc: 0.8251\n",
            "Epoch 10/30\n",
            "59199/59199 [==============================] - 13s 215us/step - loss: 0.4622 - acc: 0.8205 - val_loss: 0.4529 - val_acc: 0.8251\n",
            "Epoch 11/30\n",
            "59199/59199 [==============================] - 13s 216us/step - loss: 0.4613 - acc: 0.8205 - val_loss: 0.4545 - val_acc: 0.8251\n",
            "Epoch 12/30\n",
            "59199/59199 [==============================] - 13s 216us/step - loss: 0.4605 - acc: 0.8205 - val_loss: 0.4516 - val_acc: 0.8251\n",
            "Epoch 13/30\n",
            "59199/59199 [==============================] - 13s 216us/step - loss: 0.4600 - acc: 0.8205 - val_loss: 0.4516 - val_acc: 0.8251\n",
            "Epoch 14/30\n",
            "59199/59199 [==============================] - 13s 219us/step - loss: 0.4595 - acc: 0.8205 - val_loss: 0.4531 - val_acc: 0.8251\n",
            "Epoch 15/30\n",
            "59199/59199 [==============================] - 13s 219us/step - loss: 0.4598 - acc: 0.8205 - val_loss: 0.4511 - val_acc: 0.8251\n",
            "Epoch 16/30\n",
            "59199/59199 [==============================] - 13s 221us/step - loss: 0.4591 - acc: 0.8205 - val_loss: 0.4503 - val_acc: 0.8251\n",
            "Epoch 17/30\n",
            "59199/59199 [==============================] - 13s 220us/step - loss: 0.4582 - acc: 0.8205 - val_loss: 0.4501 - val_acc: 0.8251\n",
            "Epoch 18/30\n",
            "59199/59199 [==============================] - 13s 218us/step - loss: 0.4586 - acc: 0.8205 - val_loss: 0.4496 - val_acc: 0.8251\n",
            "Epoch 19/30\n",
            "59199/59199 [==============================] - 13s 217us/step - loss: 0.4579 - acc: 0.8205 - val_loss: 0.4491 - val_acc: 0.8251\n",
            "Epoch 20/30\n",
            "59199/59199 [==============================] - 13s 219us/step - loss: 0.4574 - acc: 0.8205 - val_loss: 0.4490 - val_acc: 0.8251\n",
            "Epoch 21/30\n",
            "59199/59199 [==============================] - 13s 223us/step - loss: 0.4572 - acc: 0.8205 - val_loss: 0.4490 - val_acc: 0.8251\n",
            "Epoch 22/30\n",
            "59199/59199 [==============================] - 13s 223us/step - loss: 0.4566 - acc: 0.8205 - val_loss: 0.4487 - val_acc: 0.8251\n",
            "Epoch 23/30\n",
            "59199/59199 [==============================] - 13s 219us/step - loss: 0.4563 - acc: 0.8205 - val_loss: 0.4476 - val_acc: 0.8251\n",
            "Epoch 24/30\n",
            "59199/59199 [==============================] - 13s 218us/step - loss: 0.4555 - acc: 0.8205 - val_loss: 0.4487 - val_acc: 0.8251\n",
            "Epoch 25/30\n",
            "59199/59199 [==============================] - 13s 219us/step - loss: 0.4551 - acc: 0.8205 - val_loss: 0.4470 - val_acc: 0.8251\n",
            "Epoch 26/30\n",
            "59199/59199 [==============================] - 13s 216us/step - loss: 0.4544 - acc: 0.8205 - val_loss: 0.4480 - val_acc: 0.8251\n",
            "Epoch 27/30\n",
            "59199/59199 [==============================] - 13s 218us/step - loss: 0.4551 - acc: 0.8205 - val_loss: 0.4463 - val_acc: 0.8251\n",
            "Epoch 28/30\n",
            "59199/59199 [==============================] - 13s 218us/step - loss: 0.4541 - acc: 0.8205 - val_loss: 0.4472 - val_acc: 0.8251\n",
            "Epoch 29/30\n",
            "59199/59199 [==============================] - 13s 217us/step - loss: 0.4538 - acc: 0.8205 - val_loss: 0.4453 - val_acc: 0.8251\n",
            "Epoch 30/30\n",
            "59199/59199 [==============================] - 13s 217us/step - loss: 0.4536 - acc: 0.8205 - val_loss: 0.4457 - val_acc: 0.8251\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16188\n",
            "           1       0.00      0.00      0.00      3546\n",
            "\n",
            "    accuracy                           0.82     19734\n",
            "   macro avg       0.41      0.50      0.45     19734\n",
            "weighted avg       0.67      0.82      0.74     19734\n",
            "\n",
            "[[16188     0]\n",
            " [ 3546     0]]\n",
            "0.8203101246579507\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WevytPrpfnpT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "6cf6646a-cb81-4ce6-abbc-eef85a2c0d7e"
      },
      "source": [
        "datos_fac.head()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_id</th>\n",
              "      <th>order_item_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>customer_zip_code_prefix</th>\n",
              "      <th>seller_id</th>\n",
              "      <th>shipping_limit_date</th>\n",
              "      <th>price</th>\n",
              "      <th>freight_value</th>\n",
              "      <th>total_value</th>\n",
              "      <th>credit_card</th>\n",
              "      <th>debit_card</th>\n",
              "      <th>boleto</th>\n",
              "      <th>voucher</th>\n",
              "      <th>not_defined</th>\n",
              "      <th>num_txn</th>\n",
              "      <th>order_status</th>\n",
              "      <th>order_purchase_timestamp</th>\n",
              "      <th>order_approved_at</th>\n",
              "      <th>order_delivered_carrier_date</th>\n",
              "      <th>order_delivered_customer_date</th>\n",
              "      <th>order_estimated_delivery_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00010242fe8c5a6d1ba2dd792cb16214</td>\n",
              "      <td>1</td>\n",
              "      <td>4244733e06e7ecb4970a6e2683c13e61</td>\n",
              "      <td>871766c5855e863f6eccc05f988b23cb</td>\n",
              "      <td>28013</td>\n",
              "      <td>48436dade18ac8b2bce089ec2a041202</td>\n",
              "      <td>2017-09-19 09:45:35</td>\n",
              "      <td>5890</td>\n",
              "      <td>1329</td>\n",
              "      <td>7219</td>\n",
              "      <td>7219.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2017-09-13 08:59:02</td>\n",
              "      <td>2017-09-13 09:45:35</td>\n",
              "      <td>2017-09-19 18:34:16</td>\n",
              "      <td>2017-09-20 23:43:48</td>\n",
              "      <td>2017-09-29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00018f77f2f0320c557190d7a144bdd3</td>\n",
              "      <td>1</td>\n",
              "      <td>e5f2d52b802189ee658865ca93d83a8f</td>\n",
              "      <td>eb28e67c4c0b83846050ddfb8a35d051</td>\n",
              "      <td>15775</td>\n",
              "      <td>dd7ddc04e1b6c2c614352b383efe2d36</td>\n",
              "      <td>2017-05-03 11:05:13</td>\n",
              "      <td>23990</td>\n",
              "      <td>1993</td>\n",
              "      <td>25983</td>\n",
              "      <td>25983.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2017-04-26 10:53:06</td>\n",
              "      <td>2017-04-26 11:05:13</td>\n",
              "      <td>2017-05-04 14:35:00</td>\n",
              "      <td>2017-05-12 16:04:24</td>\n",
              "      <td>2017-05-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000229ec398224ef6ca0657da4fc703e</td>\n",
              "      <td>1</td>\n",
              "      <td>c777355d18b72b67abbeef9df44fd0fd</td>\n",
              "      <td>3818d81c6709e39d06b2738a8d3a2474</td>\n",
              "      <td>35661</td>\n",
              "      <td>5b51032eddd242adc84c38acab88f23d</td>\n",
              "      <td>2018-01-18 14:48:30</td>\n",
              "      <td>19900</td>\n",
              "      <td>1787</td>\n",
              "      <td>21687</td>\n",
              "      <td>21687.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2018-01-14 14:33:31</td>\n",
              "      <td>2018-01-14 14:48:30</td>\n",
              "      <td>2018-01-16 12:36:48</td>\n",
              "      <td>2018-01-22 13:19:16</td>\n",
              "      <td>2018-02-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00024acbcdf0a6daa1e931b038114c75</td>\n",
              "      <td>1</td>\n",
              "      <td>7634da152a4610f1595efa32f14722fc</td>\n",
              "      <td>af861d436cfc08b2c2ddefd0ba074622</td>\n",
              "      <td>12952</td>\n",
              "      <td>9d7a1d34a5052409006425275ba1c2b4</td>\n",
              "      <td>2018-08-15 10:10:18</td>\n",
              "      <td>1299</td>\n",
              "      <td>1279</td>\n",
              "      <td>2578</td>\n",
              "      <td>2578.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2018-08-08 10:00:35</td>\n",
              "      <td>2018-08-08 10:10:18</td>\n",
              "      <td>2018-08-10 13:28:00</td>\n",
              "      <td>2018-08-14 13:32:39</td>\n",
              "      <td>2018-08-20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00042b26cf59d7ce69dfabb4e55b4fd9</td>\n",
              "      <td>1</td>\n",
              "      <td>ac6c3623068f30de03045865e4e10089</td>\n",
              "      <td>64b576fb70d441e8f1b2d7d446e483c5</td>\n",
              "      <td>13226</td>\n",
              "      <td>df560393f3a51e74553ab94004ba5c87</td>\n",
              "      <td>2017-02-13 13:57:51</td>\n",
              "      <td>19990</td>\n",
              "      <td>1814</td>\n",
              "      <td>21804</td>\n",
              "      <td>21804.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2017-02-04 13:57:51</td>\n",
              "      <td>2017-02-04 14:10:13</td>\n",
              "      <td>2017-02-16 09:46:09</td>\n",
              "      <td>2017-03-01 16:42:31</td>\n",
              "      <td>2017-03-17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           order_id  ...  order_estimated_delivery_date\n",
              "0  00010242fe8c5a6d1ba2dd792cb16214  ...                     2017-09-29\n",
              "1  00018f77f2f0320c557190d7a144bdd3  ...                     2017-05-15\n",
              "2  000229ec398224ef6ca0657da4fc703e  ...                     2018-02-05\n",
              "3  00024acbcdf0a6daa1e931b038114c75  ...                     2018-08-20\n",
              "4  00042b26cf59d7ce69dfabb4e55b4fd9  ...                     2017-03-17\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPD_j-qlfmkh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "outputId": "61ee346e-eb08-47df-b1b9-d016b490bbd7"
      },
      "source": [
        "datos_fac_prod = datos_fac.copy()\n",
        "datos_fac_prod.sort_values([\"order_id\", \"total_value\"], axis=0, ascending=False, inplace=True)\n",
        "datos_fac_prod.drop_duplicates('order_id',keep='first',inplace=True)\n",
        "#items\n",
        "datos_fac_prod['product_id']= enconder.fit_transform(datos_fac_prod[\"product_id\"])\n",
        "datos_fac_prod['order_status']= enconder.fit_transform(datos_fac_prod[\"order_status\"])\n",
        "datos_fac_prod['seller_id']= enconder.fit_transform( datos_fac_prod['seller_id'].astype('|S'))\n",
        "datos_fac_prod.head(10)\n",
        "datos_fac_prod = pd.merge(datos_fac_prod,summary[['is_churn']],on='customer_id', how='left')\n",
        "datos_fac_prod=datos_fac_prod.drop(['order_id','order_item_id','customer_id'], axis=1)\n",
        "datos_fac_prod=datos_fac_prod.drop(['shipping_limit_date','order_purchase_timestamp','order_approved_at','order_delivered_carrier_date','order_delivered_customer_date','order_estimated_delivery_date'], axis=1)\n",
        "datos_fac_prod.head()# Completo la información de los churn con 0\n",
        "datos_fac_prod['is_churn'].fillna(0, inplace=True)\n",
        "datos_fac_prod = datos_fac_prod.fillna(0)\n",
        "datos_fac_prod['credit_card'] = np.where(datos_fac_prod['credit_card']!=0, 1, 0)\n",
        "datos_fac_prod['debit_card'] = np.where(datos_fac_prod['debit_card']!=0, 1, 0)\n",
        "datos_fac_prod['boleto'] = np.where(datos_fac_prod['boleto']!=0, 1, 0)\n",
        "datos_fac_prod['voucher'] = np.where(datos_fac_prod['voucher']!=0, 1, 0)\n",
        "datos_fac_prod['not_defined'] = np.where(datos_fac_prod['not_defined']!=0, 1, 0)\n",
        "print(datos_fac_prod.is_churn.mean())\n",
        "features = datos_fac_prod.drop(['is_churn'], axis=1)\n",
        "labels = datos_fac_prod['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "print(datos_fac_prod.isnull().sum())\n",
        "features.head()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.17763971378184987\n",
            "(98666, 13)\n",
            "(98666,)\n",
            "product_id                  0\n",
            "customer_zip_code_prefix    0\n",
            "seller_id                   0\n",
            "price                       0\n",
            "freight_value               0\n",
            "total_value                 0\n",
            "credit_card                 0\n",
            "debit_card                  0\n",
            "boleto                      0\n",
            "voucher                     0\n",
            "not_defined                 0\n",
            "num_txn                     0\n",
            "order_status                0\n",
            "is_churn                    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>customer_zip_code_prefix</th>\n",
              "      <th>seller_id</th>\n",
              "      <th>price</th>\n",
              "      <th>freight_value</th>\n",
              "      <th>total_value</th>\n",
              "      <th>credit_card</th>\n",
              "      <th>debit_card</th>\n",
              "      <th>boleto</th>\n",
              "      <th>voucher</th>\n",
              "      <th>not_defined</th>\n",
              "      <th>num_txn</th>\n",
              "      <th>order_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6686</td>\n",
              "      <td>18605</td>\n",
              "      <td>2986</td>\n",
              "      <td>4300</td>\n",
              "      <td>1279</td>\n",
              "      <td>5579</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19421</td>\n",
              "      <td>13289</td>\n",
              "      <td>507</td>\n",
              "      <td>5599</td>\n",
              "      <td>872</td>\n",
              "      <td>6471</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14352</td>\n",
              "      <td>4039</td>\n",
              "      <td>2357</td>\n",
              "      <td>9990</td>\n",
              "      <td>1695</td>\n",
              "      <td>11685</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6409</td>\n",
              "      <td>81690</td>\n",
              "      <td>2938</td>\n",
              "      <td>35000</td>\n",
              "      <td>3653</td>\n",
              "      <td>38653</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9398</td>\n",
              "      <td>65077</td>\n",
              "      <td>2211</td>\n",
              "      <td>29999</td>\n",
              "      <td>4341</td>\n",
              "      <td>34340</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   product_id  customer_zip_code_prefix  ...  num_txn  order_status\n",
              "0        6686                     18605  ...      1.0             2\n",
              "1       19421                     13289  ...      1.0             2\n",
              "2       14352                      4039  ...      1.0             2\n",
              "3        6409                     81690  ...      1.0             2\n",
              "4        9398                     65077  ...      1.0             2\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxtWX8eagdyf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b7993d6-a6af-4ae5-ba1f-1e4a97653d97"
      },
      "source": [
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()\n",
        "#SVM()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inicia Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.99      0.92     16188\n",
            "           1       0.82      0.27      0.41      3546\n",
            "\n",
            "    accuracy                           0.86     19734\n",
            "   macro avg       0.84      0.63      0.66     19734\n",
            "weighted avg       0.85      0.86      0.83     19734\n",
            "\n",
            "[[15973   215]\n",
            " [ 2585   961]]\n",
            "0.8581129015911625\n",
            "inicia Regresión lineal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16188\n",
            "           1       0.00      0.00      0.00      3546\n",
            "\n",
            "    accuracy                           0.82     19734\n",
            "   macro avg       0.41      0.50      0.45     19734\n",
            "weighted avg       0.67      0.82      0.74     19734\n",
            "\n",
            "[[16188     0]\n",
            " [ 3546     0]]\n",
            "0.8203101246579507\n",
            "inicia Arboles de decisión\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16188\n",
            "           1       0.53      0.01      0.02      3546\n",
            "\n",
            "    accuracy                           0.82     19734\n",
            "   macro avg       0.67      0.50      0.46     19734\n",
            "weighted avg       0.77      0.82      0.74     19734\n",
            "\n",
            "[[16152    36]\n",
            " [ 3506    40]]\n",
            "0.8205128205128205\n",
            "inicia Gradient Boosting Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91     16188\n",
            "           1       0.93      0.08      0.14      3546\n",
            "\n",
            "    accuracy                           0.83     19734\n",
            "   macro avg       0.88      0.54      0.53     19734\n",
            "weighted avg       0.85      0.83      0.77     19734\n",
            "\n",
            "[[16166    22]\n",
            " [ 3269   277]]\n",
            "0.8332319854058985\n",
            "Inicia Deep Learning\n",
            "Train on 59199 samples, validate on 39467 samples\n",
            "Epoch 1/30\n",
            "59199/59199 [==============================] - 14s 234us/step - loss: 0.4750 - acc: 0.8205 - val_loss: 0.4642 - val_acc: 0.8251\n",
            "Epoch 2/30\n",
            "59199/59199 [==============================] - 13s 218us/step - loss: 0.4704 - acc: 0.8205 - val_loss: 0.4602 - val_acc: 0.8251\n",
            "Epoch 3/30\n",
            "59199/59199 [==============================] - 13s 218us/step - loss: 0.4694 - acc: 0.8205 - val_loss: 0.4590 - val_acc: 0.8251\n",
            "Epoch 4/30\n",
            "59199/59199 [==============================] - 13s 216us/step - loss: 0.4689 - acc: 0.8205 - val_loss: 0.4582 - val_acc: 0.8251\n",
            "Epoch 5/30\n",
            "59199/59199 [==============================] - 13s 218us/step - loss: 0.4670 - acc: 0.8205 - val_loss: 0.4565 - val_acc: 0.8251\n",
            "Epoch 6/30\n",
            "59199/59199 [==============================] - 13s 219us/step - loss: 0.4661 - acc: 0.8205 - val_loss: 0.4554 - val_acc: 0.8251\n",
            "Epoch 7/30\n",
            "59199/59199 [==============================] - 13s 216us/step - loss: 0.4649 - acc: 0.8205 - val_loss: 0.4553 - val_acc: 0.8251\n",
            "Epoch 8/30\n",
            "59199/59199 [==============================] - 13s 217us/step - loss: 0.4640 - acc: 0.8205 - val_loss: 0.4557 - val_acc: 0.8251\n",
            "Epoch 9/30\n",
            "59199/59199 [==============================] - 13s 216us/step - loss: 0.4635 - acc: 0.8205 - val_loss: 0.4529 - val_acc: 0.8251\n",
            "Epoch 10/30\n",
            "59199/59199 [==============================] - 13s 218us/step - loss: 0.4634 - acc: 0.8205 - val_loss: 0.4525 - val_acc: 0.8251\n",
            "Epoch 11/30\n",
            "59199/59199 [==============================] - 13s 221us/step - loss: 0.4624 - acc: 0.8205 - val_loss: 0.4526 - val_acc: 0.8251\n",
            "Epoch 12/30\n",
            "59199/59199 [==============================] - 13s 217us/step - loss: 0.4620 - acc: 0.8205 - val_loss: 0.4523 - val_acc: 0.8251\n",
            "Epoch 13/30\n",
            "59199/59199 [==============================] - 13s 219us/step - loss: 0.4614 - acc: 0.8205 - val_loss: 0.4525 - val_acc: 0.8251\n",
            "Epoch 14/30\n",
            "59199/59199 [==============================] - 13s 218us/step - loss: 0.4609 - acc: 0.8205 - val_loss: 0.4520 - val_acc: 0.8251\n",
            "Epoch 15/30\n",
            "59199/59199 [==============================] - 13s 220us/step - loss: 0.4603 - acc: 0.8205 - val_loss: 0.4514 - val_acc: 0.8251\n",
            "Epoch 16/30\n",
            "59199/59199 [==============================] - 13s 217us/step - loss: 0.4606 - acc: 0.8205 - val_loss: 0.4506 - val_acc: 0.8251\n",
            "Epoch 17/30\n",
            "59199/59199 [==============================] - 13s 218us/step - loss: 0.4602 - acc: 0.8205 - val_loss: 0.4516 - val_acc: 0.8251\n",
            "Epoch 18/30\n",
            "59199/59199 [==============================] - 13s 219us/step - loss: 0.4594 - acc: 0.8205 - val_loss: 0.4516 - val_acc: 0.8251\n",
            "Epoch 19/30\n",
            "59199/59199 [==============================] - 13s 217us/step - loss: 0.4593 - acc: 0.8205 - val_loss: 0.4506 - val_acc: 0.8251\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16188\n",
            "           1       0.00      0.00      0.00      3546\n",
            "\n",
            "    accuracy                           0.82     19734\n",
            "   macro avg       0.41      0.50      0.45     19734\n",
            "weighted avg       0.67      0.82      0.74     19734\n",
            "\n",
            "[[16188     0]\n",
            " [ 3546     0]]\n",
            "0.8203101246579507\n",
            "inicia Support Vector Machine\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usuPHkTOls2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "d834dd0a-71cd-4dda-d8b9-a8bf646f4e18"
      },
      "source": [
        "datos_fac_prod = datos_fac.copy()\n",
        "datos_fac_prod.sort_values([\"order_id\", \"total_value\"], axis=0, ascending=False, inplace=True)\n",
        "datos_fac_prod.drop_duplicates('order_id',keep='first',inplace=True)\n",
        "#items\n",
        "datos_fac_prod['product_id']= enconder.fit_transform(datos_fac_prod[\"product_id\"])\n",
        "datos_fac_prod['order_status']= enconder.fit_transform(datos_fac_prod[\"order_status\"])\n",
        "datos_fac_prod['seller_id']= enconder.fit_transform( datos_fac_prod['seller_id'].astype('|S'))\n",
        "datos_fac_prod.head(10)\n",
        "datos_fac_prod = pd.merge(datos_fac_prod,summary[['is_churn']],on='customer_id', how='left')\n",
        "datos_fac_prod=datos_fac_prod.drop(['order_id','order_item_id','customer_id','total_value'\t,'credit_card'\t,'debit_card'\t,'boleto'\t,'voucher'\t,'not_defined'], axis=1)\n",
        "datos_fac_prod=datos_fac_prod.drop(['shipping_limit_date','order_purchase_timestamp','order_approved_at','order_delivered_carrier_date','order_delivered_customer_date','order_estimated_delivery_date'], axis=1)\n",
        "datos_fac_prod.head()# Completo la información de los churn con 0\n",
        "datos_fac_prod['is_churn'].fillna(0, inplace=True)\n",
        "datos_fac_prod = datos_fac_prod.fillna(0)\n",
        "print(datos_fac_prod.is_churn.mean())\n",
        "features = datos_fac_prod.drop(['is_churn'], axis=1)\n",
        "labels = datos_fac_prod['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "print(datos_fac_prod.isnull().sum())\n",
        "features.head()\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.17763971378184987\n",
            "(98666, 7)\n",
            "(98666,)\n",
            "product_id                  0\n",
            "customer_zip_code_prefix    0\n",
            "seller_id                   0\n",
            "price                       0\n",
            "freight_value               0\n",
            "num_txn                     0\n",
            "order_status                0\n",
            "is_churn                    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>customer_zip_code_prefix</th>\n",
              "      <th>seller_id</th>\n",
              "      <th>price</th>\n",
              "      <th>freight_value</th>\n",
              "      <th>num_txn</th>\n",
              "      <th>order_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6686</td>\n",
              "      <td>18605</td>\n",
              "      <td>2986</td>\n",
              "      <td>4300</td>\n",
              "      <td>1279</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19421</td>\n",
              "      <td>13289</td>\n",
              "      <td>507</td>\n",
              "      <td>5599</td>\n",
              "      <td>872</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14352</td>\n",
              "      <td>4039</td>\n",
              "      <td>2357</td>\n",
              "      <td>9990</td>\n",
              "      <td>1695</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6409</td>\n",
              "      <td>81690</td>\n",
              "      <td>2938</td>\n",
              "      <td>35000</td>\n",
              "      <td>3653</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9398</td>\n",
              "      <td>65077</td>\n",
              "      <td>2211</td>\n",
              "      <td>29999</td>\n",
              "      <td>4341</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   product_id  customer_zip_code_prefix  ...  num_txn  order_status\n",
              "0        6686                     18605  ...      1.0             2\n",
              "1       19421                     13289  ...      1.0             2\n",
              "2       14352                      4039  ...      1.0             2\n",
              "3        6409                     81690  ...      1.0             2\n",
              "4        9398                     65077  ...      1.0             2\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfzBN3LbrmxA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e625a81d-df8c-43b3-9be5-c992baf7c5a3"
      },
      "source": [
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inicia Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.98      0.92     16188\n",
            "           1       0.81      0.31      0.45      3546\n",
            "\n",
            "    accuracy                           0.86     19734\n",
            "   macro avg       0.84      0.65      0.68     19734\n",
            "weighted avg       0.86      0.86      0.84     19734\n",
            "\n",
            "[[15926   262]\n",
            " [ 2448  1098]]\n",
            "0.8626735583257322\n",
            "inicia Regresión lineal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16188\n",
            "           1       0.00      0.00      0.00      3546\n",
            "\n",
            "    accuracy                           0.82     19734\n",
            "   macro avg       0.41      0.50      0.45     19734\n",
            "weighted avg       0.67      0.82      0.74     19734\n",
            "\n",
            "[[16188     0]\n",
            " [ 3546     0]]\n",
            "0.8203101246579507\n",
            "inicia Arboles de decisión\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16188\n",
            "           1       0.53      0.01      0.02      3546\n",
            "\n",
            "    accuracy                           0.82     19734\n",
            "   macro avg       0.67      0.50      0.46     19734\n",
            "weighted avg       0.77      0.82      0.74     19734\n",
            "\n",
            "[[16152    36]\n",
            " [ 3506    40]]\n",
            "0.8205128205128205\n",
            "inicia Gradient Boosting Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91     16188\n",
            "           1       0.92      0.08      0.14      3546\n",
            "\n",
            "    accuracy                           0.83     19734\n",
            "   macro avg       0.88      0.54      0.53     19734\n",
            "weighted avg       0.85      0.83      0.77     19734\n",
            "\n",
            "[[16165    23]\n",
            " [ 3269   277]]\n",
            "0.833181311442181\n",
            "Inicia Deep Learning\n",
            "Train on 59199 samples, validate on 39467 samples\n",
            "Epoch 1/30\n",
            "59199/59199 [==============================] - 13s 224us/step - loss: 0.4793 - acc: 0.8178 - val_loss: 0.4610 - val_acc: 0.8251\n",
            "Epoch 2/30\n",
            "59199/59199 [==============================] - 13s 217us/step - loss: 0.4715 - acc: 0.8205 - val_loss: 0.4603 - val_acc: 0.8251\n",
            "Epoch 3/30\n",
            "59199/59199 [==============================] - 13s 215us/step - loss: 0.4699 - acc: 0.8205 - val_loss: 0.4595 - val_acc: 0.8251\n",
            "Epoch 4/30\n",
            "59199/59199 [==============================] - 13s 214us/step - loss: 0.4697 - acc: 0.8205 - val_loss: 0.4588 - val_acc: 0.8251\n",
            "Epoch 5/30\n",
            "59199/59199 [==============================] - 12s 209us/step - loss: 0.4687 - acc: 0.8205 - val_loss: 0.4583 - val_acc: 0.8251\n",
            "Epoch 6/30\n",
            "59199/59199 [==============================] - 13s 213us/step - loss: 0.4672 - acc: 0.8205 - val_loss: 0.4566 - val_acc: 0.8251\n",
            "Epoch 7/30\n",
            "59199/59199 [==============================] - 13s 214us/step - loss: 0.4661 - acc: 0.8205 - val_loss: 0.4552 - val_acc: 0.8251\n",
            "Epoch 8/30\n",
            "59199/59199 [==============================] - 13s 212us/step - loss: 0.4649 - acc: 0.8205 - val_loss: 0.4567 - val_acc: 0.8251\n",
            "Epoch 9/30\n",
            "59199/59199 [==============================] - 13s 215us/step - loss: 0.4634 - acc: 0.8205 - val_loss: 0.4533 - val_acc: 0.8251\n",
            "Epoch 10/30\n",
            "59199/59199 [==============================] - 13s 214us/step - loss: 0.4626 - acc: 0.8205 - val_loss: 0.4527 - val_acc: 0.8251\n",
            "Epoch 11/30\n",
            "59199/59199 [==============================] - 13s 215us/step - loss: 0.4616 - acc: 0.8205 - val_loss: 0.4522 - val_acc: 0.8251\n",
            "Epoch 12/30\n",
            "59199/59199 [==============================] - 13s 216us/step - loss: 0.4616 - acc: 0.8205 - val_loss: 0.4515 - val_acc: 0.8251\n",
            "Epoch 13/30\n",
            "59199/59199 [==============================] - 13s 215us/step - loss: 0.4608 - acc: 0.8205 - val_loss: 0.4511 - val_acc: 0.8251\n",
            "Epoch 14/30\n",
            "59199/59199 [==============================] - 13s 225us/step - loss: 0.4603 - acc: 0.8205 - val_loss: 0.4509 - val_acc: 0.8251\n",
            "Epoch 15/30\n",
            "59199/59199 [==============================] - 13s 217us/step - loss: 0.4599 - acc: 0.8205 - val_loss: 0.4505 - val_acc: 0.8251\n",
            "Epoch 16/30\n",
            "59199/59199 [==============================] - 13s 215us/step - loss: 0.4593 - acc: 0.8205 - val_loss: 0.4507 - val_acc: 0.8251\n",
            "Epoch 17/30\n",
            "59199/59199 [==============================] - 13s 214us/step - loss: 0.4590 - acc: 0.8205 - val_loss: 0.4507 - val_acc: 0.8251\n",
            "Epoch 18/30\n",
            "59199/59199 [==============================] - 13s 214us/step - loss: 0.4588 - acc: 0.8205 - val_loss: 0.4502 - val_acc: 0.8251\n",
            "Epoch 19/30\n",
            "59199/59199 [==============================] - 13s 211us/step - loss: 0.4582 - acc: 0.8205 - val_loss: 0.4492 - val_acc: 0.8251\n",
            "Epoch 20/30\n",
            "59199/59199 [==============================] - 13s 214us/step - loss: 0.4576 - acc: 0.8205 - val_loss: 0.4500 - val_acc: 0.8251\n",
            "Epoch 21/30\n",
            "59199/59199 [==============================] - 13s 213us/step - loss: 0.4575 - acc: 0.8205 - val_loss: 0.4492 - val_acc: 0.8251\n",
            "Epoch 22/30\n",
            "59199/59199 [==============================] - 13s 215us/step - loss: 0.4570 - acc: 0.8205 - val_loss: 0.4489 - val_acc: 0.8251\n",
            "Epoch 23/30\n",
            "59199/59199 [==============================] - 13s 213us/step - loss: 0.4567 - acc: 0.8205 - val_loss: 0.4484 - val_acc: 0.8251\n",
            "Epoch 24/30\n",
            "59199/59199 [==============================] - 13s 214us/step - loss: 0.4566 - acc: 0.8205 - val_loss: 0.4479 - val_acc: 0.8251\n",
            "Epoch 25/30\n",
            "59199/59199 [==============================] - 13s 216us/step - loss: 0.4557 - acc: 0.8205 - val_loss: 0.4477 - val_acc: 0.8251\n",
            "Epoch 26/30\n",
            "59199/59199 [==============================] - 13s 219us/step - loss: 0.4553 - acc: 0.8205 - val_loss: 0.4486 - val_acc: 0.8251\n",
            "Epoch 27/30\n",
            "59199/59199 [==============================] - 13s 215us/step - loss: 0.4558 - acc: 0.8205 - val_loss: 0.4480 - val_acc: 0.8251\n",
            "Epoch 28/30\n",
            "59199/59199 [==============================] - 13s 215us/step - loss: 0.4549 - acc: 0.8206 - val_loss: 0.4461 - val_acc: 0.8251\n",
            "Epoch 29/30\n",
            "59199/59199 [==============================] - 13s 216us/step - loss: 0.4549 - acc: 0.8204 - val_loss: 0.4452 - val_acc: 0.8251\n",
            "Epoch 30/30\n",
            "59199/59199 [==============================] - 13s 216us/step - loss: 0.4544 - acc: 0.8210 - val_loss: 0.4455 - val_acc: 0.8251\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16188\n",
            "           1       0.00      0.00      0.00      3546\n",
            "\n",
            "    accuracy                           0.82     19734\n",
            "   macro avg       0.41      0.50      0.45     19734\n",
            "weighted avg       0.67      0.82      0.74     19734\n",
            "\n",
            "[[16188     0]\n",
            " [ 3546     0]]\n",
            "0.8203101246579507\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdmInN_5r7wI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b829017-8294-41e1-943b-b192c929334f"
      },
      "source": [
        "datos_fac_prod=datos_fac_prod.drop(['freight_value',\t'num_txn',\t'order_status'], axis=1)\n",
        "features = datos_fac_prod.drop(['is_churn'], axis=1)\n",
        "labels = datos_fac_prod['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "print(datos_fac_prod.isnull().sum())\n",
        "features.head()\n",
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(98666, 4)\n",
            "(98666,)\n",
            "product_id                  0\n",
            "customer_zip_code_prefix    0\n",
            "seller_id                   0\n",
            "price                       0\n",
            "is_churn                    0\n",
            "dtype: int64\n",
            "inicia Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.97      0.92     16188\n",
            "           1       0.70      0.36      0.48      3546\n",
            "\n",
            "    accuracy                           0.86     19734\n",
            "   macro avg       0.79      0.66      0.70     19734\n",
            "weighted avg       0.84      0.86      0.84     19734\n",
            "\n",
            "[[15646   542]\n",
            " [ 2264  1282]]\n",
            "0.8578088578088578\n",
            "inicia Regresión lineal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16188\n",
            "           1       0.00      0.00      0.00      3546\n",
            "\n",
            "    accuracy                           0.82     19734\n",
            "   macro avg       0.41      0.50      0.45     19734\n",
            "weighted avg       0.67      0.82      0.74     19734\n",
            "\n",
            "[[16188     0]\n",
            " [ 3546     0]]\n",
            "0.8203101246579507\n",
            "inicia Arboles de decisión\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16188\n",
            "           1       0.51      0.01      0.03      3546\n",
            "\n",
            "    accuracy                           0.82     19734\n",
            "   macro avg       0.66      0.51      0.46     19734\n",
            "weighted avg       0.76      0.82      0.74     19734\n",
            "\n",
            "[[16141    47]\n",
            " [ 3498    48]]\n",
            "0.8203607986216682\n",
            "inicia Gradient Boosting Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16188\n",
            "           1       0.82      0.01      0.03      3546\n",
            "\n",
            "    accuracy                           0.82     19734\n",
            "   macro avg       0.82      0.51      0.47     19734\n",
            "weighted avg       0.82      0.82      0.75     19734\n",
            "\n",
            "[[16176    12]\n",
            " [ 3493    53]]\n",
            "0.8223877571703658\n",
            "Inicia Deep Learning\n",
            "Train on 59199 samples, validate on 39467 samples\n",
            "Epoch 1/30\n",
            "59199/59199 [==============================] - 14s 229us/step - loss: 0.4765 - acc: 0.8194 - val_loss: 0.4648 - val_acc: 0.8251\n",
            "Epoch 2/30\n",
            "59199/59199 [==============================] - 13s 215us/step - loss: 0.4723 - acc: 0.8205 - val_loss: 0.4668 - val_acc: 0.8251\n",
            "Epoch 3/30\n",
            "59199/59199 [==============================] - 13s 215us/step - loss: 0.4718 - acc: 0.8205 - val_loss: 0.4619 - val_acc: 0.8251\n",
            "Epoch 4/30\n",
            "59199/59199 [==============================] - 13s 223us/step - loss: 0.4709 - acc: 0.8205 - val_loss: 0.4616 - val_acc: 0.8251\n",
            "Epoch 5/30\n",
            "59199/59199 [==============================] - 13s 223us/step - loss: 0.4709 - acc: 0.8205 - val_loss: 0.4615 - val_acc: 0.8251\n",
            "Epoch 6/30\n",
            "59199/59199 [==============================] - 13s 218us/step - loss: 0.4703 - acc: 0.8205 - val_loss: 0.4613 - val_acc: 0.8251\n",
            "Epoch 7/30\n",
            "59199/59199 [==============================] - 13s 217us/step - loss: 0.4699 - acc: 0.8205 - val_loss: 0.4620 - val_acc: 0.8251\n",
            "Epoch 8/30\n",
            "59199/59199 [==============================] - 13s 217us/step - loss: 0.4698 - acc: 0.8205 - val_loss: 0.4608 - val_acc: 0.8251\n",
            "Epoch 9/30\n",
            "59199/59199 [==============================] - 13s 217us/step - loss: 0.4697 - acc: 0.8205 - val_loss: 0.4611 - val_acc: 0.8251\n",
            "Epoch 10/30\n",
            "59199/59199 [==============================] - 13s 215us/step - loss: 0.4698 - acc: 0.8205 - val_loss: 0.4613 - val_acc: 0.8251\n",
            "Epoch 11/30\n",
            "59199/59199 [==============================] - 13s 217us/step - loss: 0.4695 - acc: 0.8205 - val_loss: 0.4611 - val_acc: 0.8251\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16188\n",
            "           1       0.00      0.00      0.00      3546\n",
            "\n",
            "    accuracy                           0.82     19734\n",
            "   macro avg       0.41      0.50      0.45     19734\n",
            "weighted avg       0.67      0.82      0.74     19734\n",
            "\n",
            "[[16188     0]\n",
            " [ 3546     0]]\n",
            "0.8203101246579507\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUE0xAxvt0xZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f2b9a3a6-64ce-4291-c794-1125a4d98dd2"
      },
      "source": [
        "datos_fac_prod=datos_fac_prod.drop(['price'], axis=1)\n",
        "features = datos_fac_prod.drop(['is_churn'], axis=1)\n",
        "labels = datos_fac_prod['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "print(datos_fac_prod.isnull().sum())\n",
        "features.head()\n",
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(98666, 3)\n",
            "(98666,)\n",
            "product_id                  0\n",
            "customer_zip_code_prefix    0\n",
            "seller_id                   0\n",
            "is_churn                    0\n",
            "dtype: int64\n",
            "inicia Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.97      0.90     16188\n",
            "           1       0.60      0.18      0.28      3546\n",
            "\n",
            "    accuracy                           0.83     19734\n",
            "   macro avg       0.72      0.58      0.59     19734\n",
            "weighted avg       0.80      0.83      0.79     19734\n",
            "\n",
            "[[15749   439]\n",
            " [ 2891   655]]\n",
            "0.8312557008209183\n",
            "inicia Regresión lineal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16188\n",
            "           1       0.00      0.00      0.00      3546\n",
            "\n",
            "    accuracy                           0.82     19734\n",
            "   macro avg       0.41      0.50      0.45     19734\n",
            "weighted avg       0.67      0.82      0.74     19734\n",
            "\n",
            "[[16188     0]\n",
            " [ 3546     0]]\n",
            "0.8203101246579507\n",
            "inicia Arboles de decisión\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16188\n",
            "           1       0.52      0.01      0.03      3546\n",
            "\n",
            "    accuracy                           0.82     19734\n",
            "   macro avg       0.67      0.51      0.46     19734\n",
            "weighted avg       0.77      0.82      0.74     19734\n",
            "\n",
            "[[16145    43]\n",
            " [ 3499    47]]\n",
            "0.8205128205128205\n",
            "inicia Gradient Boosting Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16188\n",
            "           1       0.79      0.01      0.02      3546\n",
            "\n",
            "    accuracy                           0.82     19734\n",
            "   macro avg       0.81      0.50      0.46     19734\n",
            "weighted avg       0.82      0.82      0.74     19734\n",
            "\n",
            "[[16181     7]\n",
            " [ 3519    27]]\n",
            "0.8213236039322996\n",
            "Inicia Deep Learning\n",
            "Train on 59199 samples, validate on 39467 samples\n",
            "Epoch 1/30\n",
            "59199/59199 [==============================] - 14s 233us/step - loss: 0.4774 - acc: 0.8198 - val_loss: 0.4625 - val_acc: 0.8251\n",
            "Epoch 2/30\n",
            "59199/59199 [==============================] - 13s 213us/step - loss: 0.4726 - acc: 0.8205 - val_loss: 0.4621 - val_acc: 0.8251\n",
            "Epoch 3/30\n",
            "59199/59199 [==============================] - 13s 214us/step - loss: 0.4718 - acc: 0.8205 - val_loss: 0.4625 - val_acc: 0.8251\n",
            "Epoch 4/30\n",
            "59199/59199 [==============================] - 13s 218us/step - loss: 0.4715 - acc: 0.8205 - val_loss: 0.4623 - val_acc: 0.8251\n",
            "Epoch 5/30\n",
            "59199/59199 [==============================] - 13s 217us/step - loss: 0.4716 - acc: 0.8205 - val_loss: 0.4629 - val_acc: 0.8251\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16188\n",
            "           1       0.00      0.00      0.00      3546\n",
            "\n",
            "    accuracy                           0.82     19734\n",
            "   macro avg       0.41      0.50      0.45     19734\n",
            "weighted avg       0.67      0.82      0.74     19734\n",
            "\n",
            "[[16188     0]\n",
            " [ 3546     0]]\n",
            "0.8203101246579507\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfUCjjIsnOwP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "c7646036-0d92-422e-e851-15cc59064ab3"
      },
      "source": [
        "datos = pd.get_dummies( datos_fac_prod.drop(['is_churn'], axis=1))\n",
        "datos.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>customer_zip_code_prefix</th>\n",
              "      <th>seller_id</th>\n",
              "      <th>price</th>\n",
              "      <th>freight_value</th>\n",
              "      <th>num_txn</th>\n",
              "      <th>order_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6686</td>\n",
              "      <td>18605</td>\n",
              "      <td>2986</td>\n",
              "      <td>4300</td>\n",
              "      <td>1279</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19421</td>\n",
              "      <td>13289</td>\n",
              "      <td>507</td>\n",
              "      <td>5599</td>\n",
              "      <td>872</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14352</td>\n",
              "      <td>4039</td>\n",
              "      <td>2357</td>\n",
              "      <td>9990</td>\n",
              "      <td>1695</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6409</td>\n",
              "      <td>81690</td>\n",
              "      <td>2938</td>\n",
              "      <td>35000</td>\n",
              "      <td>3653</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9398</td>\n",
              "      <td>65077</td>\n",
              "      <td>2211</td>\n",
              "      <td>29999</td>\n",
              "      <td>4341</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   product_id  customer_zip_code_prefix  ...  num_txn  order_status\n",
              "0        6686                     18605  ...      1.0             2\n",
              "1       19421                     13289  ...      1.0             2\n",
              "2       14352                      4039  ...      1.0             2\n",
              "3        6409                     81690  ...      1.0             2\n",
              "4        9398                     65077  ...      1.0             2\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q95QocnTnYGD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "a4860494-3ab7-492f-e933-f08c5a56e9ee"
      },
      "source": [
        "marcadores = datos_fac_prod['is_churn']\n",
        "marcadores.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "Name: is_churn, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzyVL_hW36iT",
        "colab_type": "text"
      },
      "source": [
        "## enfoque 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0dKuYnp3vmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "3b42d0f5-e436-48d7-930f-ca2e1faaad9a"
      },
      "source": [
        "url = 'https://github.com/masdatascience/TFM-AI/blob/master/transacciones.xlsx?raw=true'\n",
        "datos_modelo_completo = pd.ExcelFile(url)\n",
        "datos_fac = pd.read_excel(datos_modelo_completo, sheet_name='transacciones')\n",
        "dataset = datos_fac.copy()\n",
        "dataset.head()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_id</th>\n",
              "      <th>customer_order_id</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>seller_id</th>\n",
              "      <th>order_status</th>\n",
              "      <th>order_purchase_timestamp</th>\n",
              "      <th>order_approved_at</th>\n",
              "      <th>order_delivered_carrier_date</th>\n",
              "      <th>order_delivered_customer_date</th>\n",
              "      <th>order_estimated_delivery_date</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7f39ba4c9052be115350065d07583cac</td>\n",
              "      <td>d7fc82cbeafea77bd0a8fbbf6296e387</td>\n",
              "      <td>9de5797cddb92598755a0f76383ddbbb</td>\n",
              "      <td>0015a82c2db000af6aaaf3ae2ecb0532</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2017-10-18 08:16:34</td>\n",
              "      <td>2017-10-18 23:56:20</td>\n",
              "      <td>2017-10-20 14:29:01</td>\n",
              "      <td>2017-10-27 16:46:05</td>\n",
              "      <td>2017-11-09</td>\n",
              "      <td>89500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9dc8d1a6f16f1b89874c29c9d8d30447</td>\n",
              "      <td>d9442164acf4b03109425633efaa0cfc</td>\n",
              "      <td>9915eb9f74b6c11aaf04833f65b00e93</td>\n",
              "      <td>0015a82c2db000af6aaaf3ae2ecb0532</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2017-10-12 13:33:22</td>\n",
              "      <td>2017-10-12 13:49:22</td>\n",
              "      <td>2017-10-17 15:42:42</td>\n",
              "      <td>2017-10-24 20:17:44</td>\n",
              "      <td>2017-11-06</td>\n",
              "      <td>89500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d455a8cb295653b55abda06d434ab492</td>\n",
              "      <td>944b72539d7e1f7f7fc6e46639ef1fe3</td>\n",
              "      <td>3c7e305796add66698959fc7ad176f6b</td>\n",
              "      <td>0015a82c2db000af6aaaf3ae2ecb0532</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2017-09-26 22:17:05</td>\n",
              "      <td>2017-09-27 22:24:16</td>\n",
              "      <td>2017-09-29 15:53:03</td>\n",
              "      <td>2017-10-07 16:12:47</td>\n",
              "      <td>2017-10-30</td>\n",
              "      <td>89500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>006e43460a55bc60c0a437521e426529</td>\n",
              "      <td>23bfd4316e261786deed5a08231c75bc</td>\n",
              "      <td>1df0a296f852bdf1a17b085730f4b894</td>\n",
              "      <td>001cca7ae9ae17fb1caed9dfb1094831</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2017-05-11 00:24:35</td>\n",
              "      <td>2017-05-11 01:30:22</td>\n",
              "      <td>2017-05-12 12:26:32</td>\n",
              "      <td>2017-05-19 09:51:17</td>\n",
              "      <td>2017-06-02</td>\n",
              "      <td>9900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00dfb074b5c910fbd08e04691c4b712f</td>\n",
              "      <td>a5ced4926d7d8fa71e9be2b007720356</td>\n",
              "      <td>94ea9edee3656707894565f35cb8570d</td>\n",
              "      <td>001cca7ae9ae17fb1caed9dfb1094831</td>\n",
              "      <td>delivered</td>\n",
              "      <td>2017-06-08 19:43:35</td>\n",
              "      <td>2017-06-08 19:55:19</td>\n",
              "      <td>2017-06-09 15:12:41</td>\n",
              "      <td>2017-06-15 09:03:59</td>\n",
              "      <td>2017-07-10</td>\n",
              "      <td>9950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           order_id  ...  price\n",
              "0  7f39ba4c9052be115350065d07583cac  ...  89500\n",
              "1  9dc8d1a6f16f1b89874c29c9d8d30447  ...  89500\n",
              "2  d455a8cb295653b55abda06d434ab492  ...  89500\n",
              "3  006e43460a55bc60c0a437521e426529  ...   9900\n",
              "4  00dfb074b5c910fbd08e04691c4b712f  ...   9950\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5Rytd8E-UE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ejecutarPruebas(dataset_input):\n",
        "  \n",
        "  features = dataset_input.drop(['is_churn'], axis=1)\n",
        "  labels = dataset_input['is_churn']\n",
        "  print(features.shape)\n",
        "  print(labels.shape)\n",
        "  train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "  #print(dataset_input.isnull().sum())\n",
        "  features.head()\n",
        "  randomForest()\n",
        "  regresionLineal()\n",
        "  arbolDecision()\n",
        "  gradientBoost()\n",
        "  redesNeuronales()\n",
        "  #SVM()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH8Vs6244xFU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ab2d644-25fa-4d0c-a242-81a3a3412ed3"
      },
      "source": [
        "## prueba 1\n",
        "\n",
        "txn_dataset =  dataset.drop(['order_id','customer_order_id','order_approved_at','order_delivered_carrier_date','order_delivered_customer_date','order_estimated_delivery_date','order_purchase_timestamp'], axis=1)\n",
        "# get dummies\n",
        "ds_seller_id = pd.get_dummies(txn_dataset['seller_id']).iloc[:,1:]\n",
        "ds_order_status = pd.get_dummies(txn_dataset['order_status']).iloc[:,1:]\n",
        "txn_dataset =  txn_dataset.drop(['seller_id','order_status'], axis=1)\n",
        "# se integra churn y los dummies\n",
        "txn_dataset= pd.merge(txn_dataset,summary[['is_churn']],on='customer_id', how='left')\n",
        "txn_dataset = pd.concat([txn_dataset,ds_seller_id,ds_order_status], axis=1)\n",
        "features = txn_dataset.drop(['is_churn','customer_id'], axis=1)\n",
        "labels = txn_dataset['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "features.head()\n",
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100010, 3101)\n",
            "(100010,)\n",
            "inicia Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.93      0.92     16397\n",
            "           1       0.66      0.58      0.62      3605\n",
            "\n",
            "    accuracy                           0.87     20002\n",
            "   macro avg       0.79      0.76      0.77     20002\n",
            "weighted avg       0.87      0.87      0.87     20002\n",
            "\n",
            "[[15323  1074]\n",
            " [ 1507  2098]]\n",
            "0.870962903709629\n",
            "inicia Regresión lineal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16397\n",
            "           1       0.00      0.00      0.00      3605\n",
            "\n",
            "    accuracy                           0.82     20002\n",
            "   macro avg       0.41      0.50      0.45     20002\n",
            "weighted avg       0.67      0.82      0.74     20002\n",
            "\n",
            "[[16397     0]\n",
            " [ 3605     0]]\n",
            "0.8197680231976803\n",
            "inicia Arboles de decisión\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16397\n",
            "           1       0.73      0.03      0.05      3605\n",
            "\n",
            "    accuracy                           0.82     20002\n",
            "   macro avg       0.77      0.51      0.48     20002\n",
            "weighted avg       0.81      0.82      0.75     20002\n",
            "\n",
            "[[16360    37]\n",
            " [ 3507    98]]\n",
            "0.8228177182281772\n",
            "inicia Gradient Boosting Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16397\n",
            "           1       0.94      0.03      0.05      3605\n",
            "\n",
            "    accuracy                           0.82     20002\n",
            "   macro avg       0.88      0.51      0.48     20002\n",
            "weighted avg       0.84      0.82      0.75     20002\n",
            "\n",
            "[[16391     6]\n",
            " [ 3509    96]]\n",
            "0.8242675732426757\n",
            "Inicia Deep Learning\n",
            "Train on 60006 samples, validate on 40004 samples\n",
            "Epoch 1/30\n",
            "60006/60006 [==============================] - 26s 432us/step - loss: 0.3805 - acc: 0.8313 - val_loss: 0.5786 - val_acc: 0.7637\n",
            "Epoch 2/30\n",
            "60006/60006 [==============================] - 26s 428us/step - loss: 0.3402 - acc: 0.8434 - val_loss: 0.7111 - val_acc: 0.5497\n",
            "Epoch 3/30\n",
            "60006/60006 [==============================] - 26s 427us/step - loss: 0.3342 - acc: 0.8468 - val_loss: 0.6932 - val_acc: 0.5693\n",
            "Epoch 4/30\n",
            "60006/60006 [==============================] - 26s 429us/step - loss: 0.3310 - acc: 0.8475 - val_loss: 0.7489 - val_acc: 0.5612\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16397\n",
            "           1       0.00      0.00      0.00      3605\n",
            "\n",
            "    accuracy                           0.82     20002\n",
            "   macro avg       0.41      0.50      0.45     20002\n",
            "weighted avg       0.67      0.82      0.74     20002\n",
            "\n",
            "[[16397     0]\n",
            " [ 3605     0]]\n",
            "0.8197680231976803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB2VsoHzA3B7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3158729e-9332-4f0e-9141-733b1c50a5bf"
      },
      "source": [
        "## prueba 2\n",
        "\n",
        "txn_dataset =  dataset.drop(['order_id','customer_order_id','order_approved_at','order_delivered_carrier_date','order_delivered_customer_date','order_estimated_delivery_date','order_purchase_timestamp'], axis=1)\n",
        "# get dummies\n",
        "ds_seller_id = pd.get_dummies(txn_dataset['seller_id']).iloc[:,1:]\n",
        "txn_dataset['order_status']= enconder.fit_transform( txn_dataset['order_status'])\n",
        "txn_dataset =  txn_dataset.drop(['seller_id'], axis=1)\n",
        "# se integra churn y los dummies\n",
        "txn_dataset= pd.merge(txn_dataset,summary[['is_churn']],on='customer_id', how='left')\n",
        "txn_dataset = pd.concat([txn_dataset,ds_seller_id,ds_order_status], axis=1)\n",
        "txn_dataset.head()\n",
        "\n",
        "features = txn_dataset.drop(['is_churn','customer_id'], axis=1)\n",
        "labels = txn_dataset['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "features.head()\n",
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100010, 3102)\n",
            "(100010,)\n",
            "inicia Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.93      0.92     16397\n",
            "           1       0.66      0.58      0.62      3605\n",
            "\n",
            "    accuracy                           0.87     20002\n",
            "   macro avg       0.79      0.76      0.77     20002\n",
            "weighted avg       0.87      0.87      0.87     20002\n",
            "\n",
            "[[15323  1074]\n",
            " [ 1509  2096]]\n",
            "0.8708629137086291\n",
            "inicia Regresión lineal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16397\n",
            "           1       0.00      0.00      0.00      3605\n",
            "\n",
            "    accuracy                           0.82     20002\n",
            "   macro avg       0.41      0.50      0.45     20002\n",
            "weighted avg       0.67      0.82      0.74     20002\n",
            "\n",
            "[[16397     0]\n",
            " [ 3605     0]]\n",
            "0.8197680231976803\n",
            "inicia Arboles de decisión\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16397\n",
            "           1       0.73      0.03      0.05      3605\n",
            "\n",
            "    accuracy                           0.82     20002\n",
            "   macro avg       0.77      0.51      0.48     20002\n",
            "weighted avg       0.81      0.82      0.75     20002\n",
            "\n",
            "[[16360    37]\n",
            " [ 3507    98]]\n",
            "0.8228177182281772\n",
            "inicia Gradient Boosting Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16397\n",
            "           1       0.94      0.03      0.05      3605\n",
            "\n",
            "    accuracy                           0.82     20002\n",
            "   macro avg       0.88      0.51      0.48     20002\n",
            "weighted avg       0.84      0.82      0.75     20002\n",
            "\n",
            "[[16391     6]\n",
            " [ 3509    96]]\n",
            "0.8242675732426757\n",
            "Inicia Deep Learning\n",
            "Train on 60006 samples, validate on 40004 samples\n",
            "Epoch 1/30\n",
            "60006/60006 [==============================] - 25s 421us/step - loss: 0.3822 - acc: 0.8300 - val_loss: 0.5210 - val_acc: 0.8180\n",
            "Epoch 2/30\n",
            "60006/60006 [==============================] - 25s 410us/step - loss: 0.3421 - acc: 0.8449 - val_loss: 0.6025 - val_acc: 0.6717\n",
            "Epoch 3/30\n",
            "60006/60006 [==============================] - 25s 412us/step - loss: 0.3350 - acc: 0.8474 - val_loss: 0.7384 - val_acc: 0.5574\n",
            "Epoch 4/30\n",
            "60006/60006 [==============================] - 25s 412us/step - loss: 0.3323 - acc: 0.8469 - val_loss: 0.7766 - val_acc: 0.5869\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00     16397\n",
            "           1       0.18      1.00      0.31      3605\n",
            "\n",
            "    accuracy                           0.18     20002\n",
            "   macro avg       0.09      0.50      0.15     20002\n",
            "weighted avg       0.03      0.18      0.06     20002\n",
            "\n",
            "[[    0 16397]\n",
            " [    0  3605]]\n",
            "0.18023197680231975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq3t__zNCeg7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4673637e-8278-45d3-e3d3-87dae7b05624"
      },
      "source": [
        "## prueba 3\n",
        "\n",
        "txn_dataset =  dataset.drop(['order_id','customer_order_id','order_approved_at','order_delivered_carrier_date','order_delivered_customer_date','order_estimated_delivery_date','order_purchase_timestamp'], axis=1)\n",
        "# get dummies\n",
        "ds_seller_id = pd.get_dummies(txn_dataset['order_status']).iloc[:,1:]\n",
        "txn_dataset['seller_id']= enconder.fit_transform( txn_dataset['seller_id']) \n",
        "txn_dataset =  txn_dataset.drop(['order_status'], axis=1)\n",
        "# se integra churn y los dummies\n",
        "txn_dataset= pd.merge(txn_dataset,summary[['is_churn']],on='customer_id', how='left')\n",
        "txn_dataset = pd.concat([txn_dataset,ds_seller_id,ds_order_status], axis=1)\n",
        "txn_dataset.head()\n",
        "features = txn_dataset.drop(['is_churn','customer_id'], axis=1)\n",
        "labels = txn_dataset['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "features.head()\n",
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100010, 14)\n",
            "(100010,)\n",
            "inicia Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92     16397\n",
            "           1       0.66      0.54      0.60      3605\n",
            "\n",
            "    accuracy                           0.87     20002\n",
            "   macro avg       0.78      0.74      0.76     20002\n",
            "weighted avg       0.86      0.87      0.86     20002\n",
            "\n",
            "[[15391  1006]\n",
            " [ 1650  1955]]\n",
            "0.8672132786721328\n",
            "inicia Regresión lineal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16397\n",
            "           1       0.00      0.00      0.00      3605\n",
            "\n",
            "    accuracy                           0.82     20002\n",
            "   macro avg       0.41      0.50      0.45     20002\n",
            "weighted avg       0.67      0.82      0.74     20002\n",
            "\n",
            "[[16397     0]\n",
            " [ 3605     0]]\n",
            "0.8197680231976803\n",
            "inicia Arboles de decisión\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16397\n",
            "           1       0.61      0.02      0.03      3605\n",
            "\n",
            "    accuracy                           0.82     20002\n",
            "   macro avg       0.72      0.51      0.47     20002\n",
            "weighted avg       0.78      0.82      0.74     20002\n",
            "\n",
            "[[16360    37]\n",
            " [ 3547    58]]\n",
            "0.8208179182081792\n",
            "inicia Gradient Boosting Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16397\n",
            "           1       0.81      0.01      0.03      3605\n",
            "\n",
            "    accuracy                           0.82     20002\n",
            "   macro avg       0.81      0.51      0.46     20002\n",
            "weighted avg       0.82      0.82      0.74     20002\n",
            "\n",
            "[[16385    12]\n",
            " [ 3555    50]]\n",
            "0.8216678332166784\n",
            "Inicia Deep Learning\n",
            "Train on 60006 samples, validate on 40004 samples\n",
            "Epoch 1/30\n",
            "60006/60006 [==============================] - 14s 233us/step - loss: 0.4670 - acc: 0.8264 - val_loss: 0.4761 - val_acc: 0.8185\n",
            "Epoch 2/30\n",
            "60006/60006 [==============================] - 13s 223us/step - loss: 0.4621 - acc: 0.8264 - val_loss: 0.4758 - val_acc: 0.8185\n",
            "Epoch 3/30\n",
            "60006/60006 [==============================] - 13s 221us/step - loss: 0.4614 - acc: 0.8264 - val_loss: 0.4759 - val_acc: 0.8185\n",
            "Epoch 4/30\n",
            "60006/60006 [==============================] - 13s 222us/step - loss: 0.4608 - acc: 0.8264 - val_loss: 0.4816 - val_acc: 0.8185\n",
            "Epoch 5/30\n",
            "60006/60006 [==============================] - 13s 224us/step - loss: 0.4608 - acc: 0.8264 - val_loss: 0.4801 - val_acc: 0.8185\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16397\n",
            "           1       0.00      0.00      0.00      3605\n",
            "\n",
            "    accuracy                           0.82     20002\n",
            "   macro avg       0.41      0.50      0.45     20002\n",
            "weighted avg       0.67      0.82      0.74     20002\n",
            "\n",
            "[[16397     0]\n",
            " [ 3605     0]]\n",
            "0.8197680231976803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5Ik4LIAFFBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0cfe2d62-2a79-4fa8-ac75-f3b945890f85"
      },
      "source": [
        "## prueba 4\n",
        "\n",
        "txn_dataset =  dataset.drop(['order_id','customer_order_id','order_approved_at','order_delivered_carrier_date','order_delivered_customer_date','order_estimated_delivery_date','order_purchase_timestamp'], axis=1)\n",
        "# get dummies\n",
        "txn_dataset['order_status']= enconder.fit_transform( txn_dataset['order_status']) \n",
        "txn_dataset['seller_id']= enconder.fit_transform( txn_dataset['seller_id']) \n",
        "\n",
        "# se integra churn y los dummies\n",
        "txn_dataset= pd.merge(txn_dataset,summary[['is_churn']],on='customer_id', how='left')\n",
        "txn_dataset.head()\n",
        "features = txn_dataset.drop(['is_churn','customer_id'], axis=1)\n",
        "labels = txn_dataset['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "features.head()\n",
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100010, 3)\n",
            "(100010,)\n",
            "inicia Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92     16397\n",
            "           1       0.66      0.54      0.59      3605\n",
            "\n",
            "    accuracy                           0.87     20002\n",
            "   macro avg       0.78      0.74      0.76     20002\n",
            "weighted avg       0.86      0.87      0.86     20002\n",
            "\n",
            "[[15396  1001]\n",
            " [ 1656  1949]]\n",
            "0.8671632836716329\n",
            "inicia Regresión lineal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16397\n",
            "           1       0.00      0.00      0.00      3605\n",
            "\n",
            "    accuracy                           0.82     20002\n",
            "   macro avg       0.41      0.50      0.45     20002\n",
            "weighted avg       0.67      0.82      0.74     20002\n",
            "\n",
            "[[16397     0]\n",
            " [ 3605     0]]\n",
            "0.8197680231976803\n",
            "inicia Arboles de decisión\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16397\n",
            "           1       0.61      0.02      0.03      3605\n",
            "\n",
            "    accuracy                           0.82     20002\n",
            "   macro avg       0.72      0.51      0.47     20002\n",
            "weighted avg       0.78      0.82      0.74     20002\n",
            "\n",
            "[[16360    37]\n",
            " [ 3547    58]]\n",
            "0.8208179182081792\n",
            "inicia Gradient Boosting Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16397\n",
            "           1       0.83      0.01      0.03      3605\n",
            "\n",
            "    accuracy                           0.82     20002\n",
            "   macro avg       0.82      0.51      0.46     20002\n",
            "weighted avg       0.82      0.82      0.74     20002\n",
            "\n",
            "[[16387    10]\n",
            " [ 3557    48]]\n",
            "0.8216678332166784\n",
            "Inicia Deep Learning\n",
            "Train on 60006 samples, validate on 40004 samples\n",
            "Epoch 1/30\n",
            "60006/60006 [==============================] - 14s 238us/step - loss: 0.4670 - acc: 0.8260 - val_loss: 0.4775 - val_acc: 0.8185\n",
            "Epoch 2/30\n",
            "60006/60006 [==============================] - 13s 224us/step - loss: 0.4620 - acc: 0.8264 - val_loss: 0.4782 - val_acc: 0.8185\n",
            "Epoch 3/30\n",
            "60006/60006 [==============================] - 14s 235us/step - loss: 0.4614 - acc: 0.8264 - val_loss: 0.4882 - val_acc: 0.8185\n",
            "Epoch 4/30\n",
            "60006/60006 [==============================] - 14s 228us/step - loss: 0.4619 - acc: 0.8264 - val_loss: 0.4862 - val_acc: 0.8185\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     16397\n",
            "           1       0.00      0.00      0.00      3605\n",
            "\n",
            "    accuracy                           0.82     20002\n",
            "   macro avg       0.41      0.50      0.45     20002\n",
            "weighted avg       0.67      0.82      0.74     20002\n",
            "\n",
            "[[16397     0]\n",
            " [ 3605     0]]\n",
            "0.8197680231976803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wMOiJ2_FZJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "ff60ba5d-cf3a-4071-c66f-cf765805f8eb"
      },
      "source": [
        "## Prueba 5 \n",
        "url1 = 'https://github.com/masdatascience/TFM-AI/blob/master/data_model_completo.xlsx?raw=true'\n",
        "datos_modelo_completo = pd.ExcelFile(url1)\n",
        "datos_clientes = pd.read_excel(datos_modelo_completo, sheet_name='customer')\n",
        "consolidado= pd.merge(datos_clientes[['customer_id']],summary[['is_churn']],on='customer_id', how='left')\n",
        "consolidado.is_churn=consolidado.is_churn.fillna(0)\n",
        "consolidado.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>customer_state</th>\n",
              "      <th>customer_city</th>\n",
              "      <th>customer_zip_code_prefix</th>\n",
              "      <th>is_churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>\n",
              "      <td>SP</td>\n",
              "      <td>cajamar</td>\n",
              "      <td>7787</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000b849f77a49e4a4ce2b2a4ca5be3f</td>\n",
              "      <td>SP</td>\n",
              "      <td>osasco</td>\n",
              "      <td>6053</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000f46a3911fa3c0805444483337064</td>\n",
              "      <td>SC</td>\n",
              "      <td>sao jose</td>\n",
              "      <td>88115</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000f6ccb0745a6a4b88665a16c9f078</td>\n",
              "      <td>PA</td>\n",
              "      <td>belem</td>\n",
              "      <td>66812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0004aac84e0df4da2b147fca70cf8255</td>\n",
              "      <td>SP</td>\n",
              "      <td>sorocaba</td>\n",
              "      <td>18040</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        customer_id  ... is_churn\n",
              "0  0000366f3b9a7992bf8c76cfdf3221e2  ...      0.0\n",
              "1  0000b849f77a49e4a4ce2b2a4ca5be3f  ...      0.0\n",
              "2  0000f46a3911fa3c0805444483337064  ...      1.0\n",
              "3  0000f6ccb0745a6a4b88665a16c9f078  ...      0.0\n",
              "4  0004aac84e0df4da2b147fca70cf8255  ...      0.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHOr9F1UsSe8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "b6b72ee4-f013-4411-d15c-1d3a1574535d"
      },
      "source": [
        "url = 'https://github.com/masdatascience/TFM-AI/blob/master/transacciones.xlsx?raw=true'\n",
        "datos_modelo_completo = pd.ExcelFile(url)\n",
        "datos_facturacion = pd.read_excel(datos_modelo_completo, sheet_name='transacciones')\n",
        "ds_transacciones = datos_facturacion.groupby(['customer_id', 'seller_id'])['price'].sum().reset_index(name='price') \n",
        "ds_transacciones.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>seller_id</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>\n",
              "      <td>da8622b14eb17ae2831f4ac5b9dab84a</td>\n",
              "      <td>12990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000b849f77a49e4a4ce2b2a4ca5be3f</td>\n",
              "      <td>138dbe45fc62f1e244378131a6801526</td>\n",
              "      <td>1890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000f46a3911fa3c0805444483337064</td>\n",
              "      <td>3d871de0142ce09b7081e2b9d1733cb1</td>\n",
              "      <td>6900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000f6ccb0745a6a4b88665a16c9f078</td>\n",
              "      <td>ef506c96320abeedfb894c34db06f478</td>\n",
              "      <td>2599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0004aac84e0df4da2b147fca70cf8255</td>\n",
              "      <td>70a12e78e608ac31179aea7f8422044b</td>\n",
              "      <td>18000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        customer_id                         seller_id  price\n",
              "0  0000366f3b9a7992bf8c76cfdf3221e2  da8622b14eb17ae2831f4ac5b9dab84a  12990\n",
              "1  0000b849f77a49e4a4ce2b2a4ca5be3f  138dbe45fc62f1e244378131a6801526   1890\n",
              "2  0000f46a3911fa3c0805444483337064  3d871de0142ce09b7081e2b9d1733cb1   6900\n",
              "3  0000f6ccb0745a6a4b88665a16c9f078  ef506c96320abeedfb894c34db06f478   2599\n",
              "4  0004aac84e0df4da2b147fca70cf8255  70a12e78e608ac31179aea7f8422044b  18000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1A0SWjMG985",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "00cc6a4e-c93b-4694-b45d-25339445cd49"
      },
      "source": [
        "url2 = 'https://github.com/masdatascience/TFM-AI/blob/master/data_model_completo_2.xlsx?raw=true'\n",
        "datos_fac = pd.ExcelFile(url2)\n",
        "datos_fac = pd.read_excel(datos_fac, sheet_name='fac_txn')\n",
        "datos_fac_prod = datos_fac.copy()\n",
        "cruzada = datos_fac_prod.groupby(['customer_id', 'product_id']).size().reset_index(name='cantidad')\n",
        "#cruzada = cruzada.drop(['cantidad'],axis=1)\n",
        "cruzada.head()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>cantidad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>\n",
              "      <td>372645c7439f9661fbbacfd129aa92ec</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000b849f77a49e4a4ce2b2a4ca5be3f</td>\n",
              "      <td>5099f7000472b634fea8304448d20825</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000f46a3911fa3c0805444483337064</td>\n",
              "      <td>64b488de448a5324c4134ea39c28a34b</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000f6ccb0745a6a4b88665a16c9f078</td>\n",
              "      <td>2345a354a6f2033609bbf62bf5be9ef6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0004aac84e0df4da2b147fca70cf8255</td>\n",
              "      <td>c72e18b3fe2739b8d24ebf3102450f37</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        customer_id                        product_id  cantidad\n",
              "0  0000366f3b9a7992bf8c76cfdf3221e2  372645c7439f9661fbbacfd129aa92ec         1\n",
              "1  0000b849f77a49e4a4ce2b2a4ca5be3f  5099f7000472b634fea8304448d20825         1\n",
              "2  0000f46a3911fa3c0805444483337064  64b488de448a5324c4134ea39c28a34b         1\n",
              "3  0000f6ccb0745a6a4b88665a16c9f078  2345a354a6f2033609bbf62bf5be9ef6         1\n",
              "4  0004aac84e0df4da2b147fca70cf8255  c72e18b3fe2739b8d24ebf3102450f37         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHAWhHH3s2Pi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "a950dfe3-6384-49ba-e6c7-fce3e697e85b"
      },
      "source": [
        "prod = pd.get_dummies(cruzada['product_id']).iloc[:,1:]\n",
        "cruzada=cruzada.drop('product_id',axis=1)\n",
        "# se integra churn y los dummies\n",
        "cruzada = pd.concat([cruzada,prod], axis=1)\n",
        "cruzada.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>00088930e925c41fd95ebfe695fd2655</th>\n",
              "      <th>0009406fd7479715e4bef61dd91f2462</th>\n",
              "      <th>000b8f95fcb9e0096488278317764d19</th>\n",
              "      <th>000d9be29b5207b54e86aa1b1ac54872</th>\n",
              "      <th>0011c512eb256aa0dbbb544d8dffcf6e</th>\n",
              "      <th>00126f27c813603687e6ce486d909d01</th>\n",
              "      <th>001795ec6f1b187d37335e1c4704762e</th>\n",
              "      <th>001b237c0e9bb435f2e54071129237e9</th>\n",
              "      <th>001b72dfd63e9833e8c02742adf472e3</th>\n",
              "      <th>001c5d71ac6ad696d22315953758fa04</th>\n",
              "      <th>00210e41887c2a8ef9f791ebc780cc36</th>\n",
              "      <th>002159fe700ed3521f46cfcf6e941c76</th>\n",
              "      <th>0021a87d4997a48b6cef1665602be0f5</th>\n",
              "      <th>00250175f79f584c14ab5cecd80553cd</th>\n",
              "      <th>002552c0663708129c0019cc97552d7d</th>\n",
              "      <th>002959d7a0b0990fe2d69988affcbc80</th>\n",
              "      <th>002af88741ba70c7b5cf4e4a0ad7ef85</th>\n",
              "      <th>002c6dab60557c48cfd6c2222ef7fd76</th>\n",
              "      <th>002d4ea7c04739c130bb74d7e7cd1694</th>\n",
              "      <th>002ec297b1b00fb9dde7ee6ac24b6771</th>\n",
              "      <th>0030026a6ddb3b2d1d4bc225b4b4c4da</th>\n",
              "      <th>0030e635639c898b323826589761cf23</th>\n",
              "      <th>003128f981470c3e5a2e7445e4a771cd</th>\n",
              "      <th>0036bb031e69d915cd384d1b3838b5d3</th>\n",
              "      <th>003938452c98ff9ab28e9e7b4bfe97ab</th>\n",
              "      <th>003962cb74a8b43cf1034fed541a76f0</th>\n",
              "      <th>003a31970fea14fffe92ac856b8a9b97</th>\n",
              "      <th>003c0b8f6580c850bd2e32044d2ac307</th>\n",
              "      <th>003dbcabcf8e3231de657c7d9f9a5eba</th>\n",
              "      <th>004154251837f6ac124ad4374b3a8148</th>\n",
              "      <th>0042f1a9a7e0edd1400c6cd0fda065f8</th>\n",
              "      <th>0043c62d00db47eff6a6bc4cf6bfaeda</th>\n",
              "      <th>0043d1a25ef08fb6f41b8fa6f91742ab</th>\n",
              "      <th>0044d70d4e53450c0fbb8255446a797b</th>\n",
              "      <th>004552d98c5d3653af8b4dbe8def0048</th>\n",
              "      <th>004636c889c7c3dad6631f136b7fa082</th>\n",
              "      <th>004ffcbfa5aac82212a95bc972ea8a85</th>\n",
              "      <th>005030ef108f58b46b78116f754d8d38</th>\n",
              "      <th>005c6b24cc96dca3e2c01e824401030e</th>\n",
              "      <th>...</th>\n",
              "      <th>ffbceea72c6f921df4bb547275b9ca14</th>\n",
              "      <th>ffbe169d395060d7fb975c990581a329</th>\n",
              "      <th>ffbe3df3856b1fef3fee8f1264105a89</th>\n",
              "      <th>ffbfa9e143fda4420454d0f4e88a3cd5</th>\n",
              "      <th>ffbfe460c6f140cdbe4f494be6dd43be</th>\n",
              "      <th>ffc0b406806006602c5853b00ab5f7fd</th>\n",
              "      <th>ffc48c754b5bd736e2887e279d1dec72</th>\n",
              "      <th>ffc88104d219c1b767d566fd93653dd2</th>\n",
              "      <th>ffc9caf33e2d1e9f44e3e06da19085f7</th>\n",
              "      <th>ffc9d90bae2127e6a6ce6d6654267ebd</th>\n",
              "      <th>ffccf0ce5eff1a158891296990107d08</th>\n",
              "      <th>ffce5ed9e0bcc2e46796b988cdac733b</th>\n",
              "      <th>ffcfaba393e8ef71937c6e8421bc2868</th>\n",
              "      <th>ffd2365fb8224dc66883df9351d65deb</th>\n",
              "      <th>ffd246249e3225c13f40b5b91dcaa65a</th>\n",
              "      <th>ffd259a48b9b073c942884d0f3659566</th>\n",
              "      <th>ffd34459c21034d1da6df9800de0d7a3</th>\n",
              "      <th>ffd4bf4306745865e5692f69bd237893</th>\n",
              "      <th>ffd60d515c690a976c497e75cd2336f4</th>\n",
              "      <th>ffd63ee42a5c8cc5a15a1c8e2aa50011</th>\n",
              "      <th>ffd7628b0b0b98ebc549e8e4c54a59af</th>\n",
              "      <th>ffd9ac56db9194a413298faaa03cd176</th>\n",
              "      <th>ffdde3d63e889c9a9f9ec30d82a4c815</th>\n",
              "      <th>ffe013e1b4603e3b0b02fbb159d5b400</th>\n",
              "      <th>ffe0fc4e02c3559643ac063fa5cf9d07</th>\n",
              "      <th>ffe75578163d45caa52bca3529cb511e</th>\n",
              "      <th>ffe8083298f95571b4a66bfbc1c05524</th>\n",
              "      <th>ffe9468f4d890db80b7231e86931ff37</th>\n",
              "      <th>ffeb228c521d5464d1f71444da96c446</th>\n",
              "      <th>ffedbd68fa6f44e788ff6c2db8094715</th>\n",
              "      <th>ffef256879dbadcab7e77950f4f4a195</th>\n",
              "      <th>fff0a542c3c62682f23305214eaeaa24</th>\n",
              "      <th>fff1059cd247279f3726b7696c66e44e</th>\n",
              "      <th>fff28f91211774864a1000f918ed00cc</th>\n",
              "      <th>fff515ea94dbf35d54d256b3e39f0fea</th>\n",
              "      <th>fff6177642830a9a94a0f2cba5e476d1</th>\n",
              "      <th>fff81cc3158d2725c0655ab9ba0f712c</th>\n",
              "      <th>fff9553ac224cec9d15d49f5a263411f</th>\n",
              "      <th>fffdb2d0ec8d6a61f0a0a0db3f25b441</th>\n",
              "      <th>fffe9eeff12fcbd74a2f2b007dde0c58</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000b849f77a49e4a4ce2b2a4ca5be3f</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000f46a3911fa3c0805444483337064</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000f6ccb0745a6a4b88665a16c9f078</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0004aac84e0df4da2b147fca70cf8255</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32951 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        customer_id  ...  fffe9eeff12fcbd74a2f2b007dde0c58\n",
              "0  0000366f3b9a7992bf8c76cfdf3221e2  ...                                 0\n",
              "1  0000b849f77a49e4a4ce2b2a4ca5be3f  ...                                 0\n",
              "2  0000f46a3911fa3c0805444483337064  ...                                 0\n",
              "3  0000f6ccb0745a6a4b88665a16c9f078  ...                                 0\n",
              "4  0004aac84e0df4da2b147fca70cf8255  ...                                 0\n",
              "\n",
              "[5 rows x 32951 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwS5Igl2vAWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "53b4a547-b4f6-467c-b8db-4e65cc279be2"
      },
      "source": [
        "datos_todos = pd.merge(cruzada,consolidado,on='customer_id', how='left')\n",
        "#datos_todos = pd.merge(datos_todos,ds_transacciones,on='customer_id', how='left')\n",
        "ds_pruebas = datos_todos.copy()\n",
        "datos_todos.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>cantidad</th>\n",
              "      <th>is_churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>\n",
              "      <td>372645c7439f9661fbbacfd129aa92ec</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000b849f77a49e4a4ce2b2a4ca5be3f</td>\n",
              "      <td>5099f7000472b634fea8304448d20825</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000f46a3911fa3c0805444483337064</td>\n",
              "      <td>64b488de448a5324c4134ea39c28a34b</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000f6ccb0745a6a4b88665a16c9f078</td>\n",
              "      <td>2345a354a6f2033609bbf62bf5be9ef6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0004aac84e0df4da2b147fca70cf8255</td>\n",
              "      <td>c72e18b3fe2739b8d24ebf3102450f37</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        customer_id  ... is_churn\n",
              "0  0000366f3b9a7992bf8c76cfdf3221e2  ...      0.0\n",
              "1  0000b849f77a49e4a4ce2b2a4ca5be3f  ...      0.0\n",
              "2  0000f46a3911fa3c0805444483337064  ...      1.0\n",
              "3  0000f6ccb0745a6a4b88665a16c9f078  ...      0.0\n",
              "4  0004aac84e0df4da2b147fca70cf8255  ...      0.0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbeY8JKNQJk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ddc987a-30e7-4003-d515-5f6d26fbfcfb"
      },
      "source": [
        "## prueba \n",
        "enconder = LabelEncoder()\n",
        "datos_todos['customer_id']= enconder.fit_transform( ds_pruebas['customer_id'])\n",
        "datos_todos['product_id']= enconder.fit_transform( ds_pruebas['product_id'])\n",
        "#datos_todos['seller_id']= enconder.fit_transform( datos_todos['seller_id'])\n",
        "features = datos_todos.drop(['is_churn','customer_id'], axis=1)\n",
        "labels = datos_todos['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "features.head()\n",
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(102557, 2)\n",
            "(102557,)\n",
            "inicia Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.91      0.89     16904\n",
            "         1.0       0.49      0.40      0.45      3608\n",
            "\n",
            "    accuracy                           0.82     20512\n",
            "   macro avg       0.69      0.66      0.67     20512\n",
            "weighted avg       0.81      0.82      0.82     20512\n",
            "\n",
            "[[15412  1492]\n",
            " [ 2147  1461]]\n",
            "0.8225916536661466\n",
            "inicia Regresión lineal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      1.00      0.90     16904\n",
            "         1.0       0.00      0.00      0.00      3608\n",
            "\n",
            "    accuracy                           0.82     20512\n",
            "   macro avg       0.41      0.50      0.45     20512\n",
            "weighted avg       0.68      0.82      0.74     20512\n",
            "\n",
            "[[16904     0]\n",
            " [ 3608     0]]\n",
            "0.8241029641185648\n",
            "inicia Arboles de decisión\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      1.00      0.90     16904\n",
            "         1.0       0.20      0.00      0.00      3608\n",
            "\n",
            "    accuracy                           0.82     20512\n",
            "   macro avg       0.51      0.50      0.45     20512\n",
            "weighted avg       0.71      0.82      0.74     20512\n",
            "\n",
            "[[16900     4]\n",
            " [ 3607     1]]\n",
            "0.8239567082683308\n",
            "inicia Gradient Boosting Classifier\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      1.00      0.90     16904\n",
            "         1.0       0.00      0.00      0.00      3608\n",
            "\n",
            "    accuracy                           0.82     20512\n",
            "   macro avg       0.41      0.50      0.45     20512\n",
            "weighted avg       0.68      0.82      0.74     20512\n",
            "\n",
            "[[16904     0]\n",
            " [ 3608     0]]\n",
            "0.8241029641185648\n",
            "Inicia Deep Learning\n",
            "Train on 61534 samples, validate on 41023 samples\n",
            "Epoch 1/30\n",
            "61534/61534 [==============================] - 14s 232us/step - loss: 0.4759 - acc: 0.8220 - val_loss: 0.4684 - val_acc: 0.8222\n",
            "Epoch 2/30\n",
            "61534/61534 [==============================] - 14s 222us/step - loss: 0.4695 - acc: 0.8234 - val_loss: 0.4679 - val_acc: 0.8222\n",
            "Epoch 3/30\n",
            "61534/61534 [==============================] - 14s 221us/step - loss: 0.4685 - acc: 0.8234 - val_loss: 0.4688 - val_acc: 0.8222\n",
            "Epoch 4/30\n",
            "61534/61534 [==============================] - 14s 221us/step - loss: 0.4677 - acc: 0.8234 - val_loss: 0.4679 - val_acc: 0.8222\n",
            "Epoch 5/30\n",
            "27840/61534 [============>.................] - ETA: 6s - loss: 0.4696 - acc: 0.8225"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-8d66ce04838a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0marbolDecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mgradientBoost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mredesNeuronales\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-235bda33f3f7>\u001b[0m in \u001b[0;36mredesNeuronales\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m# compilar el modelo utilizando la precisión para medir el rendimiento del modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mmodelo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m   \u001b[0mresultado\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping_monitor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q178KvIJ7S4K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "f3142ab1-233b-4224-d0e5-458196dc8be5"
      },
      "source": [
        "## Prueba 5 \n",
        "\n",
        "\n",
        "\n",
        "url = 'https://github.com/masdatascience/TFM-AI/blob/master/transacciones.xlsx?raw=true'\n",
        "datos_modelo_completo = pd.ExcelFile(url)\n",
        "datos_facturacion = pd.read_excel(datos_modelo_completo, sheet_name='transacciones')\n",
        "ds_transacciones = datos_facturacion.groupby(['customer_id', 'seller_id'])['price'].sum().reset_index(name='price') \n",
        "#print(ds_transacciones.head(2)\n",
        "\n",
        "\n",
        "url1 = 'https://github.com/masdatascience/TFM-AI/blob/master/data_model_completo.xlsx?raw=true'\n",
        "datos_modelo_completo = pd.ExcelFile(url1)\n",
        "datos_clientes = pd.read_excel(datos_modelo_completo, sheet_name='customer')\n",
        "consolidado= pd.merge(datos_clientes,summary[['is_churn']],on='customer_id', how='left')\n",
        "consolidado.is_churn=consolidado.is_churn.fillna(0)\n",
        "#print(consolidado.head(2))\n",
        "\n",
        "\n",
        "\n",
        "url2 = 'https://github.com/masdatascience/TFM-AI/blob/master/data_model_completo_2.xlsx?raw=true'\n",
        "datos_fac = pd.ExcelFile(url2)\n",
        "datos_fac = pd.read_excel(datos_fac, sheet_name='fac_txn')\n",
        "datos_fac = datos_fac_prod.groupby(['customer_id', 'product_id']).size().reset_index(name='cantidad')\n",
        "#print(datos_fac.head(2))\n",
        "\n",
        "\n",
        "      \n",
        "datos_todos = pd.merge(datos_fac,consolidado,on='customer_id', how='left')\n",
        "datos_todos = pd.merge(datos_todos,ds_transacciones,on='customer_id', how='left')\n",
        "ds_pruebas = datos_todos.copy()\n",
        "datos_todos.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>cantidad</th>\n",
              "      <th>customer_state</th>\n",
              "      <th>customer_city</th>\n",
              "      <th>customer_zip_code_prefix</th>\n",
              "      <th>is_churn</th>\n",
              "      <th>seller_id</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>\n",
              "      <td>372645c7439f9661fbbacfd129aa92ec</td>\n",
              "      <td>1</td>\n",
              "      <td>SP</td>\n",
              "      <td>cajamar</td>\n",
              "      <td>7787</td>\n",
              "      <td>0.0</td>\n",
              "      <td>da8622b14eb17ae2831f4ac5b9dab84a</td>\n",
              "      <td>12990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000b849f77a49e4a4ce2b2a4ca5be3f</td>\n",
              "      <td>5099f7000472b634fea8304448d20825</td>\n",
              "      <td>1</td>\n",
              "      <td>SP</td>\n",
              "      <td>osasco</td>\n",
              "      <td>6053</td>\n",
              "      <td>0.0</td>\n",
              "      <td>138dbe45fc62f1e244378131a6801526</td>\n",
              "      <td>1890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000f46a3911fa3c0805444483337064</td>\n",
              "      <td>64b488de448a5324c4134ea39c28a34b</td>\n",
              "      <td>1</td>\n",
              "      <td>SC</td>\n",
              "      <td>sao jose</td>\n",
              "      <td>88115</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3d871de0142ce09b7081e2b9d1733cb1</td>\n",
              "      <td>6900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000f6ccb0745a6a4b88665a16c9f078</td>\n",
              "      <td>2345a354a6f2033609bbf62bf5be9ef6</td>\n",
              "      <td>1</td>\n",
              "      <td>PA</td>\n",
              "      <td>belem</td>\n",
              "      <td>66812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ef506c96320abeedfb894c34db06f478</td>\n",
              "      <td>2599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0004aac84e0df4da2b147fca70cf8255</td>\n",
              "      <td>c72e18b3fe2739b8d24ebf3102450f37</td>\n",
              "      <td>1</td>\n",
              "      <td>SP</td>\n",
              "      <td>sorocaba</td>\n",
              "      <td>18040</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70a12e78e608ac31179aea7f8422044b</td>\n",
              "      <td>18000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        customer_id  ...  price\n",
              "0  0000366f3b9a7992bf8c76cfdf3221e2  ...  12990\n",
              "1  0000b849f77a49e4a4ce2b2a4ca5be3f  ...   1890\n",
              "2  0000f46a3911fa3c0805444483337064  ...   6900\n",
              "3  0000f6ccb0745a6a4b88665a16c9f078  ...   2599\n",
              "4  0004aac84e0df4da2b147fca70cf8255  ...  18000\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "400MK3XJ8CR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "18b3f10b-68e2-480d-e1f4-39ae4b5a383b"
      },
      "source": [
        "## prueba \n",
        "enconder = LabelEncoder()\n",
        "datos_todos['customer_id']= enconder.fit_transform( ds_pruebas['customer_id'])\n",
        "datos_todos['product_id']= enconder.fit_transform( ds_pruebas['product_id'])\n",
        "datos_todos['seller_id']= enconder.fit_transform( datos_todos['seller_id'])\n",
        "datos_todos['customer_state']= enconder.fit_transform( datos_todos['customer_state'])\n",
        "datos_todos['customer_city']= enconder.fit_transform( datos_todos['customer_city'])\n",
        "\n",
        "features = datos_todos.drop(['is_churn','customer_id'], axis=1)\n",
        "labels = datos_todos['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "features.head()\n",
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(112205, 7)\n",
            "(112205,)\n",
            "inicia Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.99      0.92     18642\n",
            "         1.0       0.76      0.15      0.25      3799\n",
            "\n",
            "    accuracy                           0.85     22441\n",
            "   macro avg       0.80      0.57      0.59     22441\n",
            "weighted avg       0.84      0.85      0.80     22441\n",
            "\n",
            "[[18456   186]\n",
            " [ 3217   582]]\n",
            "0.8483579163138898\n",
            "inicia Regresión lineal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      1.00      0.91     18642\n",
            "         1.0       0.00      0.00      0.00      3799\n",
            "\n",
            "    accuracy                           0.83     22441\n",
            "   macro avg       0.42      0.50      0.45     22441\n",
            "weighted avg       0.69      0.83      0.75     22441\n",
            "\n",
            "[[18642     0]\n",
            " [ 3799     0]]\n",
            "0.8307116438661378\n",
            "inicia Arboles de decisión\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      1.00      0.91     18642\n",
            "         1.0       0.66      0.01      0.02      3799\n",
            "\n",
            "    accuracy                           0.83     22441\n",
            "   macro avg       0.75      0.51      0.47     22441\n",
            "weighted avg       0.80      0.83      0.76     22441\n",
            "\n",
            "[[18618    24]\n",
            " [ 3752    47]]\n",
            "0.8317365536295174\n",
            "inicia Gradient Boosting Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      1.00      0.91     18642\n",
            "         1.0       0.88      0.01      0.02      3799\n",
            "\n",
            "    accuracy                           0.83     22441\n",
            "   macro avg       0.86      0.51      0.47     22441\n",
            "weighted avg       0.84      0.83      0.76     22441\n",
            "\n",
            "[[18636     6]\n",
            " [ 3755    44]]\n",
            "0.832404973040417\n",
            "Inicia Deep Learning\n",
            "Train on 67323 samples, validate on 44882 samples\n",
            "Epoch 1/30\n",
            "67323/67323 [==============================] - 16s 245us/step - loss: 0.4574 - acc: 0.8326 - val_loss: 0.4526 - val_acc: 0.8311\n",
            "Epoch 2/30\n",
            "67323/67323 [==============================] - 15s 224us/step - loss: 0.4531 - acc: 0.8327 - val_loss: 0.4525 - val_acc: 0.8311\n",
            "Epoch 3/30\n",
            "67323/67323 [==============================] - 15s 226us/step - loss: 0.4521 - acc: 0.8327 - val_loss: 0.4522 - val_acc: 0.8311\n",
            "Epoch 4/30\n",
            "67323/67323 [==============================] - 15s 224us/step - loss: 0.4519 - acc: 0.8327 - val_loss: 0.4520 - val_acc: 0.8311\n",
            "Epoch 5/30\n",
            "67323/67323 [==============================] - 15s 223us/step - loss: 0.4518 - acc: 0.8327 - val_loss: 0.4516 - val_acc: 0.8311\n",
            "Epoch 6/30\n",
            "67323/67323 [==============================] - 15s 222us/step - loss: 0.4511 - acc: 0.8327 - val_loss: 0.4517 - val_acc: 0.8311\n",
            "Epoch 7/30\n",
            "67323/67323 [==============================] - 15s 221us/step - loss: 0.4509 - acc: 0.8327 - val_loss: 0.4532 - val_acc: 0.8311\n",
            "Epoch 8/30\n",
            "67323/67323 [==============================] - 15s 221us/step - loss: 0.4508 - acc: 0.8327 - val_loss: 0.4517 - val_acc: 0.8311\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      1.00      0.91     18642\n",
            "         1.0       0.00      0.00      0.00      3799\n",
            "\n",
            "    accuracy                           0.83     22441\n",
            "   macro avg       0.42      0.50      0.45     22441\n",
            "weighted avg       0.69      0.83      0.75     22441\n",
            "\n",
            "[[18642     0]\n",
            " [ 3799     0]]\n",
            "0.8307116438661378\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HCP-VyG83Eg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dd9cb861-1ad2-4a22-d151-7fb40a7042f0"
      },
      "source": [
        "features = datos_todos.drop(['is_churn'], axis=1)\n",
        "labels = datos_todos['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "features.head()\n",
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(112205, 8)\n",
            "(112205,)\n",
            "inicia Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      1.00      0.91     18642\n",
            "         1.0       0.81      0.10      0.18      3799\n",
            "\n",
            "    accuracy                           0.84     22441\n",
            "   macro avg       0.83      0.55      0.55     22441\n",
            "weighted avg       0.84      0.84      0.79     22441\n",
            "\n",
            "[[18554    88]\n",
            " [ 3413   386]]\n",
            "0.8439909094960117\n",
            "inicia Regresión lineal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      1.00      0.91     18642\n",
            "         1.0       0.00      0.00      0.00      3799\n",
            "\n",
            "    accuracy                           0.83     22441\n",
            "   macro avg       0.42      0.50      0.45     22441\n",
            "weighted avg       0.69      0.83      0.75     22441\n",
            "\n",
            "[[18642     0]\n",
            " [ 3799     0]]\n",
            "0.8307116438661378\n",
            "inicia Arboles de decisión\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      1.00      0.91     18642\n",
            "         1.0       0.66      0.01      0.02      3799\n",
            "\n",
            "    accuracy                           0.83     22441\n",
            "   macro avg       0.75      0.51      0.47     22441\n",
            "weighted avg       0.80      0.83      0.76     22441\n",
            "\n",
            "[[18618    24]\n",
            " [ 3752    47]]\n",
            "0.8317365536295174\n",
            "inicia Gradient Boosting Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      1.00      0.91     18642\n",
            "         1.0       0.87      0.01      0.02      3799\n",
            "\n",
            "    accuracy                           0.83     22441\n",
            "   macro avg       0.85      0.51      0.47     22441\n",
            "weighted avg       0.84      0.83      0.76     22441\n",
            "\n",
            "[[18635     7]\n",
            " [ 3752    47]]\n",
            "0.832494095628537\n",
            "Inicia Deep Learning\n",
            "Train on 67323 samples, validate on 44882 samples\n",
            "Epoch 1/30\n",
            "67323/67323 [==============================] - 16s 235us/step - loss: 0.4573 - acc: 0.8322 - val_loss: 0.4528 - val_acc: 0.8311\n",
            "Epoch 2/30\n",
            "67323/67323 [==============================] - 15s 226us/step - loss: 0.4535 - acc: 0.8327 - val_loss: 0.4527 - val_acc: 0.8311\n",
            "Epoch 3/30\n",
            "67323/67323 [==============================] - 15s 220us/step - loss: 0.4524 - acc: 0.8327 - val_loss: 0.4573 - val_acc: 0.8311\n",
            "Epoch 4/30\n",
            "67323/67323 [==============================] - 15s 223us/step - loss: 0.4521 - acc: 0.8327 - val_loss: 0.4527 - val_acc: 0.8311\n",
            "Epoch 5/30\n",
            "67323/67323 [==============================] - 15s 223us/step - loss: 0.4519 - acc: 0.8327 - val_loss: 0.4526 - val_acc: 0.8311\n",
            "Epoch 6/30\n",
            "67323/67323 [==============================] - 15s 225us/step - loss: 0.4513 - acc: 0.8327 - val_loss: 0.4526 - val_acc: 0.8311\n",
            "Epoch 7/30\n",
            "67323/67323 [==============================] - 15s 224us/step - loss: 0.4505 - acc: 0.8327 - val_loss: 0.4536 - val_acc: 0.8311\n",
            "Epoch 8/30\n",
            "67323/67323 [==============================] - 15s 223us/step - loss: 0.4507 - acc: 0.8327 - val_loss: 0.4526 - val_acc: 0.8311\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      1.00      0.91     18642\n",
            "         1.0       0.00      0.00      0.00      3799\n",
            "\n",
            "    accuracy                           0.83     22441\n",
            "   macro avg       0.42      0.50      0.45     22441\n",
            "weighted avg       0.69      0.83      0.75     22441\n",
            "\n",
            "[[18642     0]\n",
            " [ 3799     0]]\n",
            "0.8307116438661378\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peK57ytw9QVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4b6202d9-59de-4f0b-f90c-aa24546ffe4f"
      },
      "source": [
        "features = datos_todos.drop(['is_churn','customer_id','price','customer_zip_code_prefix'], axis=1)\n",
        "labels = datos_todos['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "features.head()\n",
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(112205, 5)\n",
            "(112205,)\n",
            "inicia Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.97      0.91     18642\n",
            "         1.0       0.55      0.17      0.26      3799\n",
            "\n",
            "    accuracy                           0.84     22441\n",
            "   macro avg       0.70      0.57      0.58     22441\n",
            "weighted avg       0.80      0.84      0.80     22441\n",
            "\n",
            "[[18122   520]\n",
            " [ 3165   634]]\n",
            "0.8357916313889755\n",
            "inicia Regresión lineal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      1.00      0.91     18642\n",
            "         1.0       0.00      0.00      0.00      3799\n",
            "\n",
            "    accuracy                           0.83     22441\n",
            "   macro avg       0.42      0.50      0.45     22441\n",
            "weighted avg       0.69      0.83      0.75     22441\n",
            "\n",
            "[[18642     0]\n",
            " [ 3799     0]]\n",
            "0.8307116438661378\n",
            "inicia Arboles de decisión\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      1.00      0.91     18642\n",
            "         1.0       0.61      0.02      0.03      3799\n",
            "\n",
            "    accuracy                           0.83     22441\n",
            "   macro avg       0.72      0.51      0.47     22441\n",
            "weighted avg       0.79      0.83      0.76     22441\n",
            "\n",
            "[[18600    42]\n",
            " [ 3734    65]]\n",
            "0.8317365536295174\n",
            "inicia Gradient Boosting Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      1.00      0.91     18642\n",
            "         1.0       0.86      0.01      0.02      3799\n",
            "\n",
            "    accuracy                           0.83     22441\n",
            "   macro avg       0.85      0.50      0.46     22441\n",
            "weighted avg       0.84      0.83      0.76     22441\n",
            "\n",
            "[[18636     6]\n",
            " [ 3761    38]]\n",
            "0.8321376052760572\n",
            "Inicia Deep Learning\n",
            "Train on 67323 samples, validate on 44882 samples\n",
            "Epoch 1/30\n",
            "67323/67323 [==============================] - 16s 236us/step - loss: 0.4576 - acc: 0.8319 - val_loss: 0.4533 - val_acc: 0.8311\n",
            "Epoch 2/30\n",
            "67323/67323 [==============================] - 15s 224us/step - loss: 0.4535 - acc: 0.8327 - val_loss: 0.4531 - val_acc: 0.8311\n",
            "Epoch 3/30\n",
            "67323/67323 [==============================] - 15s 224us/step - loss: 0.4528 - acc: 0.8327 - val_loss: 0.4531 - val_acc: 0.8311\n",
            "Epoch 4/30\n",
            "67323/67323 [==============================] - 15s 226us/step - loss: 0.4526 - acc: 0.8327 - val_loss: 0.4529 - val_acc: 0.8311\n",
            "Epoch 5/30\n",
            "67323/67323 [==============================] - 15s 226us/step - loss: 0.4523 - acc: 0.8327 - val_loss: 0.4526 - val_acc: 0.8311\n",
            "Epoch 6/30\n",
            "67323/67323 [==============================] - 15s 229us/step - loss: 0.4520 - acc: 0.8327 - val_loss: 0.4524 - val_acc: 0.8311\n",
            "Epoch 7/30\n",
            "67323/67323 [==============================] - 15s 227us/step - loss: 0.4517 - acc: 0.8327 - val_loss: 0.4527 - val_acc: 0.8311\n",
            "Epoch 8/30\n",
            "67323/67323 [==============================] - 15s 226us/step - loss: 0.4516 - acc: 0.8327 - val_loss: 0.4541 - val_acc: 0.8311\n",
            "Epoch 9/30\n",
            "67323/67323 [==============================] - 15s 227us/step - loss: 0.4516 - acc: 0.8327 - val_loss: 0.4535 - val_acc: 0.8311\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      1.00      0.91     18642\n",
            "         1.0       0.00      0.00      0.00      3799\n",
            "\n",
            "    accuracy                           0.83     22441\n",
            "   macro avg       0.42      0.50      0.45     22441\n",
            "weighted avg       0.69      0.83      0.75     22441\n",
            "\n",
            "[[18642     0]\n",
            " [ 3799     0]]\n",
            "0.8307116438661378\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odQd0Ko4-mMj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "780aa9e6-df20-4e62-8086-de56512f9f17"
      },
      "source": [
        "features = datos_todos.drop(['is_churn','customer_id','price','customer_zip_code_prefix','customer_state','cantidad'], axis=1)\n",
        "labels = datos_todos['is_churn']\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "features.head()\n",
        "randomForest()\n",
        "regresionLineal()\n",
        "arbolDecision()\n",
        "gradientBoost()\n",
        "redesNeuronales()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(112205, 3)\n",
            "(112205,)\n",
            "inicia Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.97      0.91     18642\n",
            "         1.0       0.56      0.19      0.28      3799\n",
            "\n",
            "    accuracy                           0.84     22441\n",
            "   macro avg       0.71      0.58      0.60     22441\n",
            "weighted avg       0.80      0.84      0.80     22441\n",
            "\n",
            "[[18077   565]\n",
            " [ 3080   719]]\n",
            "0.8375740831513747\n",
            "inicia Regresión lineal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      1.00      0.91     18642\n",
            "         1.0       0.00      0.00      0.00      3799\n",
            "\n",
            "    accuracy                           0.83     22441\n",
            "   macro avg       0.42      0.50      0.45     22441\n",
            "weighted avg       0.69      0.83      0.75     22441\n",
            "\n",
            "[[18642     0]\n",
            " [ 3799     0]]\n",
            "0.8307116438661378\n",
            "inicia Arboles de decisión\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      1.00      0.91     18642\n",
            "         1.0       0.61      0.02      0.03      3799\n",
            "\n",
            "    accuracy                           0.83     22441\n",
            "   macro avg       0.72      0.51      0.47     22441\n",
            "weighted avg       0.79      0.83      0.76     22441\n",
            "\n",
            "[[18600    42]\n",
            " [ 3734    65]]\n",
            "0.8317365536295174\n",
            "inicia Gradient Boosting Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      1.00      0.91     18642\n",
            "         1.0       0.87      0.01      0.02      3799\n",
            "\n",
            "    accuracy                           0.83     22441\n",
            "   macro avg       0.85      0.51      0.47     22441\n",
            "weighted avg       0.84      0.83      0.76     22441\n",
            "\n",
            "[[18635     7]\n",
            " [ 3751    48]]\n",
            "0.832538656922597\n",
            "Inicia Deep Learning\n",
            "Train on 67323 samples, validate on 44882 samples\n",
            "Epoch 1/30\n",
            "67323/67323 [==============================] - 16s 244us/step - loss: 0.4575 - acc: 0.8326 - val_loss: 0.4537 - val_acc: 0.8311\n",
            "Epoch 2/30\n",
            "67323/67323 [==============================] - 15s 228us/step - loss: 0.4537 - acc: 0.8327 - val_loss: 0.4531 - val_acc: 0.8311\n",
            "Epoch 3/30\n",
            "67323/67323 [==============================] - 15s 229us/step - loss: 0.4528 - acc: 0.8327 - val_loss: 0.4540 - val_acc: 0.8311\n",
            "Epoch 4/30\n",
            "67323/67323 [==============================] - 15s 226us/step - loss: 0.4531 - acc: 0.8327 - val_loss: 0.4532 - val_acc: 0.8311\n",
            "Epoch 5/30\n",
            "67323/67323 [==============================] - 15s 224us/step - loss: 0.4533 - acc: 0.8327 - val_loss: 0.4545 - val_acc: 0.8311\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      1.00      0.91     18642\n",
            "         1.0       0.00      0.00      0.00      3799\n",
            "\n",
            "    accuracy                           0.83     22441\n",
            "   macro avg       0.42      0.50      0.45     22441\n",
            "weighted avg       0.69      0.83      0.75     22441\n",
            "\n",
            "[[18642     0]\n",
            " [ 3799     0]]\n",
            "0.8307116438661378\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}